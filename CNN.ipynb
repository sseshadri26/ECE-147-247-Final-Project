{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten,Dropout\n",
    "from keras.layers import LSTM,Conv2D,BatchNormalization,MaxPooling2D,Reshape\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = np.load(\"X_test.npy\")\n",
    "y_test = np.load(\"y_test.npy\")\n",
    "person_train_valid = np.load(\"person_train_valid.npy\")\n",
    "X_train_valid = np.load(\"X_train_valid.npy\")\n",
    "y_train_valid = np.load(\"y_train_valid.npy\")\n",
    "person_test = np.load(\"person_test.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shape of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training/Valid data shape: (2115, 22, 1000)\n",
      "Test data shape: (1772, 22, 250, 1)\n",
      "Training/Valid target shape: (2115,)\n",
      "Test target shape: (1772, 64, 4, 4)\n",
      "Person train/valid shape: (2115,)\n",
      "Person test shape: (443,)\n"
     ]
    }
   ],
   "source": [
    "print ('Training/Valid data shape: {}'.format(X_train_valid.shape))\n",
    "print ('Test data shape: {}'.format(X_test.shape))\n",
    "print ('Training/Valid target shape: {}'.format(y_train_valid.shape))\n",
    "print ('Test target shape: {}'.format(y_test.shape))\n",
    "print ('Person train/valid shape: {}'.format(person_train_valid.shape))\n",
    "print ('Person test shape: {}'.format(person_test.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(237, 22, 1000)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = (person_train_valid==0)\n",
    "idx = np.squeeze(idx)\n",
    "X_train_valid[idx].shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x15303ba7bb0>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Loading and visualizing the data\n",
    "\n",
    "## Loading the dataset\n",
    "\n",
    "\n",
    "X_test = np.load(\"X_test.npy\")\n",
    "y_test = np.load(\"y_test.npy\")\n",
    "person_train_valid = np.squeeze(np.load(\"person_train_valid.npy\"))\n",
    "X_train_valid = np.load(\"X_train_valid.npy\")\n",
    "y_train_valid = np.load(\"y_train_valid.npy\")\n",
    "person_test = np.squeeze(np.load(\"person_test.npy\"))\n",
    "\n",
    "\n",
    "## Adjusting the labels so that \n",
    "\n",
    "# Cue onset left - 0\n",
    "# Cue onset right - 1\n",
    "# Cue onset foot - 2\n",
    "# Cue onset tongue - 3\n",
    "\n",
    "y_train_valid -= 769\n",
    "y_test -= 769\n",
    "\n",
    "## Visualizing the data\n",
    "\n",
    "ch_data = X_train_valid[:,8,:] # extracts the 9th channel from the data\n",
    "\n",
    "\n",
    "class_0_ind = np.where(y_train_valid == 0) # finds the indices where the label is 0\n",
    "ch_data_class_0 = ch_data[class_0_ind] # finds the data where label is 0\n",
    "avg_ch_data_class_0 = np.mean(ch_data_class_0,axis=0) # finds the average representation of the 9th channel when label is 0\n",
    "\n",
    "\n",
    "class_1_ind = np.where(y_train_valid == 1)\n",
    "ch_data_class_1 = ch_data[class_1_ind]\n",
    "avg_ch_data_class_1 = np.mean(ch_data_class_1,axis=0)\n",
    "\n",
    "class_2_ind = np.where(y_train_valid == 2)\n",
    "ch_data_class_2 = ch_data[class_2_ind]\n",
    "avg_ch_data_class_2 = np.mean(ch_data_class_2,axis=0)\n",
    "\n",
    "class_3_ind = np.where(y_train_valid == 3)\n",
    "ch_data_class_3 = ch_data[class_3_ind]\n",
    "avg_ch_data_class_3 = np.mean(ch_data_class_3,axis=0)\n",
    "\n",
    "\n",
    "plt.plot(np.arange(1000),avg_ch_data_class_0)\n",
    "plt.plot(np.arange(1000),avg_ch_data_class_1)\n",
    "plt.plot(np.arange(1000),avg_ch_data_class_2)\n",
    "plt.plot(np.arange(1000),avg_ch_data_class_3)\n",
    "plt.axvline(x=500, label='line at t=500',c='cyan')\n",
    "\n",
    "plt.legend([\"Cue Onset left\", \"Cue Onset right\", \"Cue onset foot\", \"Cue onset tongue\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2115,)\n",
      "(443,)\n"
     ]
    }
   ],
   "source": [
    "print(person_train_valid.shape)\n",
    "print(person_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep(X,y,sub_sample,average,noise):\n",
    "    \n",
    "    total_X = None\n",
    "    total_y = None\n",
    "    \n",
    "    # Trimming the data (sample,22,1000) -> (sample,22,500)\n",
    "    X = X[:,:,0:500]\n",
    "    print('Shape of X after trimming:',X.shape)\n",
    "    \n",
    "    # Maxpooling the data (sample,22,1000) -> (sample,22,500/sub_sample)\n",
    "    X_max = np.max(X.reshape(X.shape[0], X.shape[1], -1, sub_sample), axis=3)\n",
    "\n",
    "    \n",
    "    total_X = X_max\n",
    "    total_y = y\n",
    "    print('Shape of X after maxpooling:',total_X.shape)\n",
    "    \n",
    "    # Averaging + noise \n",
    "    X_average = np.mean(X.reshape(X.shape[0], X.shape[1], -1, average),axis=3)\n",
    "    X_average = X_average + np.random.normal(0.0, 0.5, X_average.shape)\n",
    "    \n",
    "    total_X = np.vstack((total_X, X_average))\n",
    "    total_y = np.hstack((total_y, y))\n",
    "    print('Shape of X after averaging+noise and concatenating:',total_X.shape)\n",
    "    \n",
    "    # Subsampling\n",
    "    \n",
    "    for i in range(sub_sample):\n",
    "        \n",
    "        X_subsample = X[:, :, i::sub_sample] + \\\n",
    "                            (np.random.normal(0.0, 0.5, X[:, :,i::sub_sample].shape) if noise else 0.0)\n",
    "            \n",
    "        total_X = np.vstack((total_X, X_subsample))\n",
    "        total_y = np.hstack((total_y, y))\n",
    "        \n",
    "    \n",
    "    print('Shape of X after subsampling and concatenating:',total_X.shape)\n",
    "    return total_X,total_y\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X after trimming: (2115, 22, 500)\n",
      "Shape of X after maxpooling: (2115, 22, 25)\n",
      "Shape of X after averaging+noise and concatenating: (4230, 22, 25)\n",
      "Shape of X after subsampling and concatenating: (46530, 22, 25)\n"
     ]
    }
   ],
   "source": [
    "X_train_valid_prep,y_train_valid_prep = data_prep(X_train_valid,y_train_valid,20,20,True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X after trimming: (2115, 22, 500)\n",
      "Shape of X after maxpooling: (2115, 22, 250)\n",
      "Shape of X after averaging+noise and concatenating: (4230, 22, 250)\n",
      "Shape of X after subsampling and concatenating: (8460, 22, 250)\n"
     ]
    }
   ],
   "source": [
    "X_train_valid_prep,person_train_valid_prep = data_prep(X_train_valid,person_train_valid,2,2,True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X after trimming: (1740, 22, 500)\n",
      "Shape of X after maxpooling: (1740, 22, 250)\n",
      "Shape of X after averaging+noise and concatenating: (3480, 22, 250)\n",
      "Shape of X after subsampling and concatenating: (6960, 22, 250)\n",
      "Shape of X after trimming: (375, 22, 500)\n",
      "Shape of X after maxpooling: (375, 22, 250)\n",
      "Shape of X after averaging+noise and concatenating: (750, 22, 250)\n",
      "Shape of X after subsampling and concatenating: (1500, 22, 250)\n",
      "Shape of X after trimming: (443, 22, 500)\n",
      "Shape of X after maxpooling: (443, 22, 250)\n",
      "Shape of X after averaging+noise and concatenating: (886, 22, 250)\n",
      "Shape of X after subsampling and concatenating: (1772, 22, 250)\n",
      "Shape of testing set: (1772, 22, 250)\n",
      "Shape of testing labels: (1772,)\n",
      "Shape of training set: (6960, 22, 250)\n",
      "Shape of validation set: (1500, 22, 250)\n",
      "Shape of training labels: (6960,)\n",
      "Shape of validation labels: (1500,)\n",
      "Shape of training labels after categorical conversion: (6960, 4)\n",
      "Shape of validation labels after categorical conversion: (1500, 4)\n",
      "Shape of test labels after categorical conversion: (1772, 4)\n",
      "Shape of training set after adding width info: (6960, 22, 250, 1)\n",
      "Shape of validation set after adding width info: (1500, 22, 250, 1)\n",
      "Shape of test set after adding width info: (1772, 22, 250, 1)\n",
      "Shape of training set after dimension reshaping: (6960, 250, 1, 22)\n",
      "Shape of validation set after dimension reshaping: (1500, 250, 1, 22)\n",
      "Shape of test set after dimension reshaping: (1772, 250, 1, 22)\n"
     ]
    }
   ],
   "source": [
    "## Random splitting and reshaping the data\n",
    "# First generating the training and validation indices using random splitting\n",
    "\n",
    "ind_valid = np.random.choice(2115, 375, replace=False)\n",
    "ind_train = np.array(list(set(range(2115)).difference(set(ind_valid))))\n",
    "\n",
    "# Creating the training and validation sets using the generated indices\n",
    "(X_train, X_valid) = X_train_valid[ind_train], X_train_valid[ind_valid] \n",
    "(y_train, y_valid) = y_train_valid[ind_train], y_train_valid[ind_valid]\n",
    "\n",
    "\n",
    "## Preprocessing the dataset\n",
    "x_train,y_train = data_prep(X_train,y_train,2,2,True)\n",
    "x_valid,y_valid = data_prep(X_valid,y_valid,2,2,True)\n",
    "X_test_prep,y_test_prep = data_prep(X_test,y_test,2,2,True)\n",
    "\n",
    "\n",
    "print('Shape of testing set:',X_test_prep.shape)\n",
    "print('Shape of testing labels:',y_test_prep.shape)\n",
    "\n",
    "print('Shape of training set:',x_train.shape)\n",
    "print('Shape of validation set:',x_valid.shape)\n",
    "print('Shape of training labels:',y_train.shape)\n",
    "print('Shape of validation labels:',y_valid.shape)\n",
    "\n",
    "\n",
    "\n",
    "# Converting the labels to categorical variables for multiclass classification\n",
    "y_train = to_categorical(y_train, 4)\n",
    "y_valid = to_categorical(y_valid, 4)\n",
    "y_test = to_categorical(y_test_prep, 4)\n",
    "print('Shape of training labels after categorical conversion:',y_train.shape)\n",
    "print('Shape of validation labels after categorical conversion:',y_valid.shape)\n",
    "print('Shape of test labels after categorical conversion:',y_test.shape)\n",
    "\n",
    "# Adding width of the segment to be 1\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
    "x_valid = x_valid.reshape(x_valid.shape[0], x_valid.shape[1], x_train.shape[2], 1)\n",
    "x_test = X_test_prep.reshape(X_test_prep.shape[0], X_test_prep.shape[1], X_test_prep.shape[2], 1)\n",
    "print('Shape of training set after adding width info:',x_train.shape)\n",
    "print('Shape of validation set after adding width info:',x_valid.shape)\n",
    "print('Shape of test set after adding width info:',x_test.shape)\n",
    "\n",
    "\n",
    "# Reshaping the training and validation dataset\n",
    "x_train = np.swapaxes(x_train, 1,3)\n",
    "x_train = np.swapaxes(x_train, 1,2)\n",
    "x_valid = np.swapaxes(x_valid, 1,3)\n",
    "x_valid = np.swapaxes(x_valid, 1,2)\n",
    "x_test = np.swapaxes(x_test, 1,3)\n",
    "x_test = np.swapaxes(x_test, 1,2)\n",
    "print('Shape of training set after dimension reshaping:',x_train.shape)\n",
    "print('Shape of validation set after dimension reshaping:',x_valid.shape)\n",
    "print('Shape of test set after dimension reshaping:',x_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_12 (Conv2D)          (None, 250, 1, 25)        5525      \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 84, 1, 25)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 84, 1, 25)        100       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 84, 1, 25)         0         \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 84, 1, 50)         12550     \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 28, 1, 50)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 28, 1, 50)        200       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 28, 1, 50)         0         \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 28, 1, 100)        50100     \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 10, 1, 100)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 10, 1, 100)       400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 10, 1, 100)        0         \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 10, 1, 200)        200200    \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPoolin  (None, 4, 1, 200)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 4, 1, 200)        800       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 4, 1, 200)         0         \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 800)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4)                 3204      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 273,079\n",
      "Trainable params: 272,329\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Building the CNN model using sequential class\n",
    "basic_cnn_model = Sequential()\n",
    "\n",
    "# Conv. block 1\n",
    "basic_cnn_model.add(Conv2D(filters=25, kernel_size=(10,1), padding='same', activation='elu', input_shape=(250,1,22)))\n",
    "basic_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same')) # Read the keras documentation\n",
    "basic_cnn_model.add(BatchNormalization())\n",
    "basic_cnn_model.add(Dropout(0.5))\n",
    "\n",
    "# Conv. block 2\n",
    "basic_cnn_model.add(Conv2D(filters=50, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "basic_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "basic_cnn_model.add(BatchNormalization())\n",
    "basic_cnn_model.add(Dropout(0.5))\n",
    "\n",
    "# Conv. block 3\n",
    "basic_cnn_model.add(Conv2D(filters=100, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "basic_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "basic_cnn_model.add(BatchNormalization())\n",
    "basic_cnn_model.add(Dropout(0.5))\n",
    "\n",
    "# Conv. block 4\n",
    "basic_cnn_model.add(Conv2D(filters=200, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "basic_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "basic_cnn_model.add(BatchNormalization())\n",
    "basic_cnn_model.add(Dropout(0.5))\n",
    "\n",
    "# Output layer with Softmax activation\n",
    "basic_cnn_model.add(Flatten()) # Flattens the input\n",
    "basic_cnn_model.add(Dense(4, activation='softmax')) # Output FC layer with softmax activation\n",
    "\n",
    "\n",
    "# Printing the model summary\n",
    "basic_cnn_model.summary()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "learning_rate = 1e-3\n",
    "epochs = 50\n",
    "cnn_optimizer = keras.optimizers.Adam(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_cnn_model.compile(loss='categorical_crossentropy',\n",
    "                 optimizer=cnn_optimizer,\n",
    "                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.3341 - accuracy: 0.8774 - val_loss: 0.8967 - val_accuracy: 0.6813\n",
      "Epoch 2/25\n",
      "109/109 [==============================] - 3s 23ms/step - loss: 0.3111 - accuracy: 0.8822 - val_loss: 0.9756 - val_accuracy: 0.6673\n",
      "Epoch 3/25\n",
      "109/109 [==============================] - 3s 23ms/step - loss: 0.2965 - accuracy: 0.8884 - val_loss: 0.9689 - val_accuracy: 0.6980\n",
      "Epoch 4/25\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.3099 - accuracy: 0.8884 - val_loss: 0.8954 - val_accuracy: 0.6880\n",
      "Epoch 5/25\n",
      "109/109 [==============================] - 3s 23ms/step - loss: 0.3069 - accuracy: 0.8839 - val_loss: 0.9777 - val_accuracy: 0.7033\n",
      "Epoch 6/25\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.3122 - accuracy: 0.8825 - val_loss: 0.8834 - val_accuracy: 0.7020\n",
      "Epoch 7/25\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.2929 - accuracy: 0.8897 - val_loss: 0.9698 - val_accuracy: 0.6827\n",
      "Epoch 8/25\n",
      "109/109 [==============================] - 3s 23ms/step - loss: 0.2860 - accuracy: 0.8953 - val_loss: 0.9504 - val_accuracy: 0.6933\n",
      "Epoch 9/25\n",
      "109/109 [==============================] - 2s 23ms/step - loss: 0.2917 - accuracy: 0.8927 - val_loss: 0.9190 - val_accuracy: 0.7120\n",
      "Epoch 10/25\n",
      "109/109 [==============================] - 2s 23ms/step - loss: 0.2906 - accuracy: 0.8927 - val_loss: 0.9950 - val_accuracy: 0.7000\n",
      "Epoch 11/25\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.2752 - accuracy: 0.8958 - val_loss: 0.9289 - val_accuracy: 0.6953\n",
      "Epoch 12/25\n",
      "109/109 [==============================] - 3s 23ms/step - loss: 0.2722 - accuracy: 0.9007 - val_loss: 0.9962 - val_accuracy: 0.6900\n",
      "Epoch 13/25\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.2668 - accuracy: 0.8987 - val_loss: 0.9970 - val_accuracy: 0.6953\n",
      "Epoch 14/25\n",
      "109/109 [==============================] - 3s 23ms/step - loss: 0.2814 - accuracy: 0.8940 - val_loss: 0.9910 - val_accuracy: 0.6847\n",
      "Epoch 15/25\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.2702 - accuracy: 0.8999 - val_loss: 1.0389 - val_accuracy: 0.6653\n",
      "Epoch 16/25\n",
      "109/109 [==============================] - 3s 23ms/step - loss: 0.2729 - accuracy: 0.9009 - val_loss: 0.9135 - val_accuracy: 0.7160\n",
      "Epoch 17/25\n",
      "109/109 [==============================] - 3s 23ms/step - loss: 0.2487 - accuracy: 0.9052 - val_loss: 0.9373 - val_accuracy: 0.7013\n",
      "Epoch 18/25\n",
      "109/109 [==============================] - 3s 23ms/step - loss: 0.2466 - accuracy: 0.9047 - val_loss: 0.9790 - val_accuracy: 0.7053\n",
      "Epoch 19/25\n",
      "109/109 [==============================] - 3s 23ms/step - loss: 0.2450 - accuracy: 0.9121 - val_loss: 0.9927 - val_accuracy: 0.6933\n",
      "Epoch 20/25\n",
      "109/109 [==============================] - 3s 23ms/step - loss: 0.2586 - accuracy: 0.9034 - val_loss: 0.9492 - val_accuracy: 0.7093\n",
      "Epoch 21/25\n",
      "109/109 [==============================] - 3s 23ms/step - loss: 0.2367 - accuracy: 0.9109 - val_loss: 0.9659 - val_accuracy: 0.6980\n",
      "Epoch 22/25\n",
      "109/109 [==============================] - 3s 23ms/step - loss: 0.2598 - accuracy: 0.9042 - val_loss: 0.9948 - val_accuracy: 0.7073\n",
      "Epoch 23/25\n",
      "109/109 [==============================] - 3s 23ms/step - loss: 0.2501 - accuracy: 0.9052 - val_loss: 0.9467 - val_accuracy: 0.7040\n",
      "Epoch 24/25\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.2422 - accuracy: 0.9102 - val_loss: 0.9940 - val_accuracy: 0.6987\n",
      "Epoch 25/25\n",
      "109/109 [==============================] - 3s 23ms/step - loss: 0.2340 - accuracy: 0.9152 - val_loss: 0.9851 - val_accuracy: 0.7040\n"
     ]
    }
   ],
   "source": [
    "basic_cnn_model_results = basic_cnn_model.fit(x_train,\n",
    "             y_train,\n",
    "             batch_size=64,\n",
    "             epochs=25,\n",
    "             validation_data=(x_valid, y_valid), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of the basic CNN model: 0.7014672756195068\n"
     ]
    }
   ],
   "source": [
    "cnn_score = basic_cnn_model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test accuracy of the basic CNN model:',cnn_score[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 250, 1, 32)        7072      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 84, 1, 32)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 84, 1, 32)        128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 84, 1, 32)         0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 84, 1, 64)         20544     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 28, 1, 64)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 28, 1, 64)        256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 28, 1, 64)         0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 28, 1, 128)        82048     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 10, 1, 128)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 10, 1, 128)       512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 10, 1, 128)        0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 10, 1, 256)        327936    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 4, 1, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 4, 1, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 4, 1, 256)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4)                 4100      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 443,620\n",
      "Trainable params: 442,660\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Building the CNN model using sequential class\n",
    "tunedcnn = Sequential()\n",
    "\n",
    "# Conv. block 1\n",
    "tunedcnn.add(Conv2D(filters=32, kernel_size=(10,1), padding='same', activation='elu', input_shape=(250,1,22)))\n",
    "tunedcnn.add(MaxPooling2D(pool_size=(3,1), padding='same')) # Read the keras documentation\n",
    "tunedcnn.add(BatchNormalization())\n",
    "tunedcnn.add(Dropout(0.5))\n",
    "\n",
    "# Conv. block 2\n",
    "tunedcnn.add(Conv2D(filters=64, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "tunedcnn.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "tunedcnn.add(BatchNormalization())\n",
    "tunedcnn.add(Dropout(0.5))\n",
    "\n",
    "# Conv. block 3\n",
    "tunedcnn.add(Conv2D(filters=128, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "tunedcnn.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "tunedcnn.add(BatchNormalization())\n",
    "tunedcnn.add(Dropout(0.5))\n",
    "\n",
    "# Conv. block 4\n",
    "tunedcnn.add(Conv2D(filters=256, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "tunedcnn.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "tunedcnn.add(BatchNormalization())\n",
    "tunedcnn.add(Dropout(0.5))\n",
    "\n",
    "# Output layer with Softmax activation\n",
    "tunedcnn.add(Flatten()) # Flattens the input\n",
    "tunedcnn.add(Dense(4, activation='softmax')) # Output FC layer with softmax activation\n",
    "\n",
    "\n",
    "# Printing the model summary\n",
    "tunedcnn.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "109/109 [==============================] - 4s 32ms/step - loss: 1.9837 - accuracy: 0.3109 - val_loss: 2.0210 - val_accuracy: 0.3860\n",
      "Epoch 2/50\n",
      "109/109 [==============================] - 3s 31ms/step - loss: 1.4152 - accuracy: 0.3836 - val_loss: 1.4707 - val_accuracy: 0.3620\n",
      "Epoch 3/50\n",
      "109/109 [==============================] - 3s 32ms/step - loss: 1.2360 - accuracy: 0.4504 - val_loss: 1.2445 - val_accuracy: 0.4047\n",
      "Epoch 4/50\n",
      "109/109 [==============================] - 3s 29ms/step - loss: 1.1575 - accuracy: 0.5022 - val_loss: 1.2536 - val_accuracy: 0.4373\n",
      "Epoch 5/50\n",
      "109/109 [==============================] - 3s 28ms/step - loss: 1.0772 - accuracy: 0.5401 - val_loss: 1.0770 - val_accuracy: 0.5707\n",
      "Epoch 6/50\n",
      "109/109 [==============================] - 3s 29ms/step - loss: 0.9903 - accuracy: 0.5892 - val_loss: 1.0465 - val_accuracy: 0.5660\n",
      "Epoch 7/50\n",
      "109/109 [==============================] - 3s 29ms/step - loss: 0.9314 - accuracy: 0.6157 - val_loss: 1.0455 - val_accuracy: 0.5733\n",
      "Epoch 8/50\n",
      "109/109 [==============================] - 3s 29ms/step - loss: 0.8790 - accuracy: 0.6431 - val_loss: 0.9990 - val_accuracy: 0.5667\n",
      "Epoch 9/50\n",
      "109/109 [==============================] - 3s 30ms/step - loss: 0.8097 - accuracy: 0.6757 - val_loss: 0.9286 - val_accuracy: 0.6333\n",
      "Epoch 10/50\n",
      "109/109 [==============================] - 3s 31ms/step - loss: 0.7804 - accuracy: 0.6869 - val_loss: 0.9582 - val_accuracy: 0.5893\n",
      "Epoch 11/50\n",
      "109/109 [==============================] - 3s 32ms/step - loss: 0.7169 - accuracy: 0.7175 - val_loss: 0.9522 - val_accuracy: 0.6353\n",
      "Epoch 12/50\n",
      "109/109 [==============================] - 3s 32ms/step - loss: 0.7172 - accuracy: 0.7168 - val_loss: 0.9403 - val_accuracy: 0.6127\n",
      "Epoch 13/50\n",
      "109/109 [==============================] - 4s 33ms/step - loss: 0.6514 - accuracy: 0.7415 - val_loss: 0.9218 - val_accuracy: 0.6293\n",
      "Epoch 14/50\n",
      "109/109 [==============================] - 3s 31ms/step - loss: 0.5985 - accuracy: 0.7667 - val_loss: 0.8930 - val_accuracy: 0.6560\n",
      "Epoch 15/50\n",
      "109/109 [==============================] - 3s 31ms/step - loss: 0.5807 - accuracy: 0.7753 - val_loss: 0.9509 - val_accuracy: 0.6273\n",
      "Epoch 16/50\n",
      "109/109 [==============================] - 3s 30ms/step - loss: 0.5502 - accuracy: 0.7931 - val_loss: 0.8868 - val_accuracy: 0.6533\n",
      "Epoch 17/50\n",
      "109/109 [==============================] - 4s 32ms/step - loss: 0.5233 - accuracy: 0.7955 - val_loss: 0.8837 - val_accuracy: 0.6780\n",
      "Epoch 18/50\n",
      "109/109 [==============================] - 4s 34ms/step - loss: 0.4883 - accuracy: 0.8034 - val_loss: 0.9085 - val_accuracy: 0.6613\n",
      "Epoch 19/50\n",
      "109/109 [==============================] - 3s 30ms/step - loss: 0.4730 - accuracy: 0.8191 - val_loss: 0.9266 - val_accuracy: 0.6487\n",
      "Epoch 20/50\n",
      "109/109 [==============================] - 4s 32ms/step - loss: 0.4320 - accuracy: 0.8315 - val_loss: 0.9543 - val_accuracy: 0.6673\n",
      "Epoch 21/50\n",
      "109/109 [==============================] - 3s 31ms/step - loss: 0.4460 - accuracy: 0.8293 - val_loss: 0.9161 - val_accuracy: 0.6780\n",
      "Epoch 22/50\n",
      "109/109 [==============================] - 3s 29ms/step - loss: 0.4130 - accuracy: 0.8407 - val_loss: 1.0157 - val_accuracy: 0.6440\n",
      "Epoch 23/50\n",
      "109/109 [==============================] - 3s 30ms/step - loss: 0.3887 - accuracy: 0.8481 - val_loss: 0.9009 - val_accuracy: 0.6893\n",
      "Epoch 24/50\n",
      "109/109 [==============================] - 4s 33ms/step - loss: 0.3896 - accuracy: 0.8491 - val_loss: 0.9412 - val_accuracy: 0.6713\n",
      "Epoch 25/50\n",
      "109/109 [==============================] - 3s 31ms/step - loss: 0.3592 - accuracy: 0.8651 - val_loss: 0.9258 - val_accuracy: 0.6653\n",
      "Epoch 26/50\n",
      "109/109 [==============================] - 3s 31ms/step - loss: 0.3381 - accuracy: 0.8730 - val_loss: 0.9430 - val_accuracy: 0.6660\n",
      "Epoch 27/50\n",
      "109/109 [==============================] - 3s 30ms/step - loss: 0.3559 - accuracy: 0.8635 - val_loss: 0.9579 - val_accuracy: 0.6587\n",
      "Epoch 28/50\n",
      "109/109 [==============================] - 3s 30ms/step - loss: 0.3216 - accuracy: 0.8760 - val_loss: 0.9055 - val_accuracy: 0.6800\n",
      "Epoch 29/50\n",
      "109/109 [==============================] - 4s 32ms/step - loss: 0.3315 - accuracy: 0.8770 - val_loss: 0.9047 - val_accuracy: 0.6820\n",
      "Epoch 30/50\n",
      "109/109 [==============================] - 3s 30ms/step - loss: 0.3064 - accuracy: 0.8835 - val_loss: 0.9250 - val_accuracy: 0.6787\n",
      "Epoch 31/50\n",
      "109/109 [==============================] - 3s 28ms/step - loss: 0.2926 - accuracy: 0.8905 - val_loss: 0.9618 - val_accuracy: 0.6700\n",
      "Epoch 32/50\n",
      "109/109 [==============================] - 3s 28ms/step - loss: 0.2986 - accuracy: 0.8897 - val_loss: 0.9601 - val_accuracy: 0.6813\n",
      "Epoch 33/50\n",
      "109/109 [==============================] - 3s 28ms/step - loss: 0.2744 - accuracy: 0.8987 - val_loss: 0.9628 - val_accuracy: 0.6867\n",
      "Epoch 34/50\n",
      "109/109 [==============================] - 3s 28ms/step - loss: 0.2732 - accuracy: 0.9010 - val_loss: 0.9399 - val_accuracy: 0.6873\n",
      "Epoch 35/50\n",
      "109/109 [==============================] - 3s 28ms/step - loss: 0.2466 - accuracy: 0.9045 - val_loss: 1.0051 - val_accuracy: 0.6800\n",
      "Epoch 36/50\n",
      "109/109 [==============================] - 3s 28ms/step - loss: 0.2427 - accuracy: 0.9105 - val_loss: 1.0356 - val_accuracy: 0.6633\n",
      "Epoch 37/50\n",
      "109/109 [==============================] - 3s 28ms/step - loss: 0.2505 - accuracy: 0.9086 - val_loss: 1.0026 - val_accuracy: 0.6767\n",
      "Epoch 38/50\n",
      "109/109 [==============================] - 3s 28ms/step - loss: 0.2392 - accuracy: 0.9098 - val_loss: 0.9431 - val_accuracy: 0.6920\n",
      "Epoch 39/50\n",
      "109/109 [==============================] - 3s 28ms/step - loss: 0.2508 - accuracy: 0.9091 - val_loss: 0.9944 - val_accuracy: 0.6773\n",
      "Epoch 40/50\n",
      "109/109 [==============================] - 3s 28ms/step - loss: 0.2371 - accuracy: 0.9136 - val_loss: 0.9725 - val_accuracy: 0.6880\n",
      "Epoch 41/50\n",
      "109/109 [==============================] - 3s 28ms/step - loss: 0.2257 - accuracy: 0.9159 - val_loss: 0.9096 - val_accuracy: 0.7107\n",
      "Epoch 42/50\n",
      "109/109 [==============================] - 3s 28ms/step - loss: 0.2184 - accuracy: 0.9201 - val_loss: 0.9997 - val_accuracy: 0.6847\n",
      "Epoch 43/50\n",
      "109/109 [==============================] - 3s 28ms/step - loss: 0.2261 - accuracy: 0.9174 - val_loss: 0.9864 - val_accuracy: 0.6900\n",
      "Epoch 44/50\n",
      "109/109 [==============================] - 3s 28ms/step - loss: 0.2314 - accuracy: 0.9155 - val_loss: 1.0091 - val_accuracy: 0.6747\n",
      "Epoch 45/50\n",
      "109/109 [==============================] - 3s 28ms/step - loss: 0.2153 - accuracy: 0.9198 - val_loss: 1.0068 - val_accuracy: 0.7067\n",
      "Epoch 46/50\n",
      "109/109 [==============================] - 3s 28ms/step - loss: 0.2297 - accuracy: 0.9149 - val_loss: 1.0056 - val_accuracy: 0.6780\n",
      "Epoch 47/50\n",
      "109/109 [==============================] - 3s 28ms/step - loss: 0.2013 - accuracy: 0.9234 - val_loss: 0.9791 - val_accuracy: 0.7000\n",
      "Epoch 48/50\n",
      "109/109 [==============================] - 3s 28ms/step - loss: 0.2051 - accuracy: 0.9218 - val_loss: 1.0106 - val_accuracy: 0.6840\n",
      "Epoch 49/50\n",
      "109/109 [==============================] - 3s 28ms/step - loss: 0.1997 - accuracy: 0.9254 - val_loss: 0.9838 - val_accuracy: 0.6947\n",
      "Epoch 50/50\n",
      "109/109 [==============================] - 3s 29ms/step - loss: 0.1897 - accuracy: 0.9292 - val_loss: 1.0303 - val_accuracy: 0.6780\n"
     ]
    }
   ],
   "source": [
    "tunedcnn.compile(loss='categorical_crossentropy',\n",
    "                 optimizer=cnn_optimizer,\n",
    "                 metrics=['accuracy'])\n",
    "tunedcnn_results = tunedcnn.fit(x_train,\n",
    "             y_train,\n",
    "             batch_size=64,\n",
    "             epochs=50,\n",
    "             validation_data=(x_valid, y_valid), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of the basic CNN model: 0.6760722398757935\n"
     ]
    }
   ],
   "source": [
    "tunedscore = tunedcnn.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test accuracy of the basic CNN model:',tunedscore[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 3, 3, 2, 2, 3, 3, 0, 2, 3, 2, 0, 1, 1, 3, 3, 2, 0, 2, 1,\n",
       "       0, 1, 3, 2, 0, 1, 1, 3, 2, 2, 1, 1, 2, 0, 0, 0, 0, 3, 1, 2, 0, 1,\n",
       "       3, 2, 0, 3, 2, 1, 1, 2, 0, 3, 3, 1, 1, 3, 3, 2, 1, 1, 3, 1, 0, 1,\n",
       "       1, 1, 2, 0, 0, 1, 3, 2, 2, 0, 1, 2, 0, 2, 3, 2, 0, 1, 3, 0, 0, 3,\n",
       "       3, 0, 3, 2, 1, 1, 0, 2, 0, 3, 1, 3, 1, 0, 0, 1, 2, 0, 0, 3, 2, 2,\n",
       "       3, 1, 3, 1, 0, 0, 1, 3, 1, 0, 0, 0, 3, 2, 3, 0, 3, 0, 2, 3, 2, 1,\n",
       "       3, 1, 1, 3, 0, 1, 3, 0, 0, 2, 2, 0, 2, 3, 3, 1, 0, 3, 0, 3, 1, 2,\n",
       "       1, 0, 2, 0, 1, 3, 0, 1, 2, 2, 1, 2, 3, 1, 0, 3, 1, 1, 1, 3, 2, 0,\n",
       "       1, 2, 1, 3, 2, 3, 3, 1, 1, 3, 1, 2, 2, 1, 3, 2, 3, 3, 2, 2, 1, 3,\n",
       "       2, 1, 3, 1, 0, 0, 3, 2, 0, 0, 0, 3, 3, 2, 0, 1, 0, 2, 0, 0, 3, 2,\n",
       "       1, 1, 3, 1, 0, 2, 0, 1, 2, 3, 1, 1, 2, 0, 0, 1, 0, 3, 3, 3, 2, 0,\n",
       "       0, 1, 1, 3, 0, 3, 0, 2, 3, 0, 1, 0, 0, 0, 3, 1, 2, 0, 1, 3, 0, 0,\n",
       "       2, 3, 3, 2, 1, 0, 0, 3, 2, 2, 3, 1, 1, 3, 2, 0, 1, 0, 0, 2, 1, 2,\n",
       "       0, 2, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 2, 1, 0, 0, 1, 0, 3, 2, 3, 3,\n",
       "       3, 1, 2, 0, 2, 2, 3, 1, 2, 0, 0, 0, 1, 0, 1, 3, 0, 1, 1, 1, 2, 3,\n",
       "       1, 1, 3, 0, 0, 1, 1, 1, 2, 1, 1, 3, 0, 1, 3, 3, 3, 3, 1, 2, 3, 1,\n",
       "       2, 1, 0, 3, 2, 2, 3, 2, 0, 1, 3, 0, 3, 1, 1, 3, 3, 1, 1, 3, 0, 3,\n",
       "       1, 1, 3, 2, 0, 0, 3, 1, 2, 3, 0, 1, 1, 3, 2, 1, 3, 2, 1, 1, 2, 2,\n",
       "       0, 2, 0, 3, 1, 2, 2, 0, 2, 0, 2, 0, 3, 3, 3, 2, 3, 2, 0, 1, 0, 2,\n",
       "       1, 2, 3, 3, 1, 1, 3, 0, 1, 1, 2, 0, 2, 1, 3, 1, 0, 1, 0, 0, 1, 0,\n",
       "       3, 2, 1])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = (person_train_valid==0)\n",
    "idx = np.squeeze(idx)\n",
    "X_train_valid_p = X_train_valid[idx]\n",
    "y_train_valid_p = y_train_valid[idx]\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X after trimming: (187, 22, 500)\n",
      "Shape of X after maxpooling: (187, 22, 250)\n",
      "Shape of X after averaging+noise and concatenating: (374, 22, 250)\n",
      "Shape of X after subsampling and concatenating: (748, 22, 250)\n",
      "Shape of X after trimming: (50, 22, 500)\n",
      "Shape of X after maxpooling: (50, 22, 250)\n",
      "Shape of X after averaging+noise and concatenating: (100, 22, 250)\n",
      "Shape of X after subsampling and concatenating: (200, 22, 250)\n",
      "Shape of X after trimming: (443, 22, 500)\n",
      "Shape of X after maxpooling: (443, 22, 250)\n",
      "Shape of X after averaging+noise and concatenating: (886, 22, 250)\n",
      "Shape of X after subsampling and concatenating: (1772, 22, 250)\n",
      "Shape of testing set: (1772, 22, 250)\n",
      "Shape of testing labels: (1772,)\n",
      "Shape of training set: (748, 22, 250)\n",
      "Shape of validation set: (200, 22, 250)\n",
      "Shape of training labels: (748,)\n",
      "Shape of validation labels: (200,)\n",
      "Shape of training labels after categorical conversion: (748, 4)\n",
      "Shape of validation labels after categorical conversion: (200, 4)\n",
      "Shape of test labels after categorical conversion: (1772, 4)\n",
      "Shape of training set after adding width info: (748, 22, 250, 1)\n",
      "Shape of validation set after adding width info: (200, 22, 250, 1)\n",
      "Shape of test set after adding width info: (1772, 1, 22, 250)\n",
      "Shape of training set after dimension reshaping: (748, 250, 1, 22)\n",
      "Shape of validation set after dimension reshaping: (200, 250, 1, 22)\n",
      "Shape of test set after dimension reshaping: (1772, 250, 1, 22)\n"
     ]
    }
   ],
   "source": [
    "## Random splitting and reshaping the data\n",
    "# First generating the training and validation indices using random splitting\n",
    "\n",
    "ind_valid = np.random.choice(237, 50, replace=False)\n",
    "ind_train = np.array(list(set(range(237)).difference(set(ind_valid))))\n",
    "\n",
    "# Creating the training and validation sets using the generated indices\n",
    "(X_train_p, X_valid_p) = X_train_valid_p[ind_train], X_train_valid_p[ind_valid] \n",
    "(y_train_p, y_valid_p) = y_train_valid_p[ind_train], y_train_valid_p[ind_valid]\n",
    "\n",
    "\n",
    "## Preprocessing the dataset\n",
    "X_train_p,y_train_p = data_prep(X_train_p,y_train_p,2,2,True)\n",
    "X_valid_p,y_valid_p = data_prep(X_valid_p,y_valid_p,2,2,True)\n",
    "## Use whole test set\n",
    "X_test_prep,y_test_prep = data_prep(X_test,y_test,2,2,True)\n",
    "\n",
    "\n",
    "print('Shape of testing set:',X_test_prep.shape)\n",
    "print('Shape of testing labels:',y_test_prep.shape)\n",
    "\n",
    "print('Shape of training set:',X_train_p.shape)\n",
    "print('Shape of validation set:',X_valid_p.shape)\n",
    "print('Shape of training labels:',y_train_p.shape)\n",
    "print('Shape of validation labels:',y_valid_p.shape)\n",
    "\n",
    "\n",
    "\n",
    "# Converting the labels to categorical variables for multiclass classification\n",
    "y_train_p = to_categorical(y_train_p, 4)\n",
    "y_valid_p = to_categorical(y_valid_p, 4)\n",
    "y_test = to_categorical(y_test_prep, 4)\n",
    "print('Shape of training labels after categorical conversion:',y_train_p.shape)\n",
    "print('Shape of validation labels after categorical conversion:',y_valid_p.shape)\n",
    "print('Shape of test labels after categorical conversion:',y_test.shape)\n",
    "\n",
    "# Adding width of the segment to be 1\n",
    "X_train_p = X_train_p.reshape(X_train_p.shape[0], X_train_p.shape[1], X_train_p.shape[2], 1)\n",
    "X_valid_p = X_valid_p.reshape(X_valid_p.shape[0], X_valid_p.shape[1], X_valid_p.shape[2], 1)\n",
    "X_test = X_test_prep.reshape(X_test_prep.shape[0], X_test_prep.shape[1], X_test_prep.shape[2], 1)\n",
    "print('Shape of training set after adding width info:',X_train_p.shape)\n",
    "print('Shape of validation set after adding width info:',X_valid_p.shape)\n",
    "print('Shape of test set after adding width info:',x_test.shape)\n",
    "\n",
    "\n",
    "# Reshaping the training and validation dataset\n",
    "X_train_p = np.swapaxes(X_train_p, 1,3)\n",
    "X_train_p = np.swapaxes(X_train_p, 1,2)\n",
    "X_valid_p = np.swapaxes(X_valid_p, 1,3)\n",
    "X_valid_p = np.swapaxes(X_valid_p, 1,2)\n",
    "X_test = np.swapaxes(X_test, 1,3)\n",
    "X_test = np.swapaxes(X_test, 1,2)\n",
    "print('Shape of training set after dimension reshaping:',X_train_p.shape)\n",
    "print('Shape of validation set after dimension reshaping:',X_valid_p.shape)\n",
    "print('Shape of test set after dimension reshaping:',X_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 250, 1, 25)        5525      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 84, 1, 25)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 84, 1, 25)        100       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 84, 1, 25)         0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 84, 1, 50)         12550     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 28, 1, 50)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 28, 1, 50)        200       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 28, 1, 50)         0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 28, 1, 100)        50100     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 10, 1, 100)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 10, 1, 100)       400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 10, 1, 100)        0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 10, 1, 200)        200200    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 4, 1, 200)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 4, 1, 200)        800       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 4, 1, 200)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 800)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4)                 3204      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 273,079\n",
      "Trainable params: 272,329\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Building the CNN model using sequential class\n",
    "p_cnn_model = Sequential()\n",
    "\n",
    "# Conv. block 1\n",
    "p_cnn_model.add(Conv2D(filters=25, kernel_size=(10,1), padding='same', activation='elu', input_shape=(250,1,22)))\n",
    "p_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same')) # Read the keras documentation\n",
    "p_cnn_model.add(BatchNormalization())\n",
    "p_cnn_model.add(Dropout(0.5))\n",
    "\n",
    "# Conv. block 2\n",
    "p_cnn_model.add(Conv2D(filters=50, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "p_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "p_cnn_model.add(BatchNormalization())\n",
    "p_cnn_model.add(Dropout(0.5))\n",
    "\n",
    "# Conv. block 3\n",
    "p_cnn_model.add(Conv2D(filters=100, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "p_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "p_cnn_model.add(BatchNormalization())\n",
    "p_cnn_model.add(Dropout(0.5))\n",
    "\n",
    "# Conv. block 4\n",
    "p_cnn_model.add(Conv2D(filters=200, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "p_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "p_cnn_model.add(BatchNormalization())\n",
    "p_cnn_model.add(Dropout(0.5))\n",
    "\n",
    "# Output layer with Softmax activation\n",
    "p_cnn_model.add(Flatten()) # Flattens the input\n",
    "p_cnn_model.add(Dense(4, activation='softmax')) # Output FC layer with softmax activation\n",
    "\n",
    "\n",
    "# Printing the model summary\n",
    "p_cnn_model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "12/12 [==============================] - 1s 39ms/step - loss: 2.5606 - accuracy: 0.3222 - val_loss: 8.6891 - val_accuracy: 0.3350\n",
      "Epoch 2/25\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 1.9537 - accuracy: 0.4091 - val_loss: 14.5486 - val_accuracy: 0.4050\n",
      "Epoch 3/25\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 1.5508 - accuracy: 0.4545 - val_loss: 20.1632 - val_accuracy: 0.4050\n",
      "Epoch 4/25\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 1.2487 - accuracy: 0.5401 - val_loss: 10.3002 - val_accuracy: 0.3650\n",
      "Epoch 5/25\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.9871 - accuracy: 0.6083 - val_loss: 6.6200 - val_accuracy: 0.4050\n",
      "Epoch 6/25\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.8333 - accuracy: 0.6644 - val_loss: 6.3666 - val_accuracy: 0.3850\n",
      "Epoch 7/25\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.6055 - accuracy: 0.7701 - val_loss: 3.8767 - val_accuracy: 0.3800\n",
      "Epoch 8/25\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.5454 - accuracy: 0.7834 - val_loss: 3.0840 - val_accuracy: 0.4150\n",
      "Epoch 9/25\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.5021 - accuracy: 0.8021 - val_loss: 2.9643 - val_accuracy: 0.4650\n",
      "Epoch 10/25\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.4070 - accuracy: 0.8316 - val_loss: 2.5397 - val_accuracy: 0.4450\n",
      "Epoch 11/25\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 0.3946 - accuracy: 0.8583 - val_loss: 2.3458 - val_accuracy: 0.4700\n",
      "Epoch 12/25\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.3319 - accuracy: 0.8824 - val_loss: 2.4269 - val_accuracy: 0.4100\n",
      "Epoch 13/25\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.3355 - accuracy: 0.8610 - val_loss: 2.3898 - val_accuracy: 0.4800\n",
      "Epoch 14/25\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 0.2734 - accuracy: 0.8824 - val_loss: 2.1871 - val_accuracy: 0.4900\n",
      "Epoch 15/25\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.2920 - accuracy: 0.8810 - val_loss: 1.9738 - val_accuracy: 0.4750\n",
      "Epoch 16/25\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.2194 - accuracy: 0.9198 - val_loss: 2.0144 - val_accuracy: 0.4950\n",
      "Epoch 17/25\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.2122 - accuracy: 0.9198 - val_loss: 1.9195 - val_accuracy: 0.5150\n",
      "Epoch 18/25\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.1744 - accuracy: 0.9425 - val_loss: 1.9616 - val_accuracy: 0.5350\n",
      "Epoch 19/25\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.1876 - accuracy: 0.9225 - val_loss: 1.9318 - val_accuracy: 0.5350\n",
      "Epoch 20/25\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.1645 - accuracy: 0.9385 - val_loss: 1.9754 - val_accuracy: 0.5500\n",
      "Epoch 21/25\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 0.1899 - accuracy: 0.9211 - val_loss: 1.9116 - val_accuracy: 0.5700\n",
      "Epoch 22/25\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.1651 - accuracy: 0.9452 - val_loss: 1.9472 - val_accuracy: 0.5400\n",
      "Epoch 23/25\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.1729 - accuracy: 0.9465 - val_loss: 1.9641 - val_accuracy: 0.5550\n",
      "Epoch 24/25\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 0.1385 - accuracy: 0.9452 - val_loss: 1.9865 - val_accuracy: 0.5150\n",
      "Epoch 25/25\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.1404 - accuracy: 0.9545 - val_loss: 2.0861 - val_accuracy: 0.5150\n"
     ]
    }
   ],
   "source": [
    "p_cnn_model.compile(loss='categorical_crossentropy',\n",
    "                 optimizer=cnn_optimizer,\n",
    "                 metrics=['accuracy'])\n",
    "p_cnn_model_results = p_cnn_model.fit(X_train_p,\n",
    "             y_train_p,\n",
    "             batch_size=64,\n",
    "             epochs=25,\n",
    "             validation_data=(X_valid_p, y_valid_p), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of the basic CNN model: 0.3882618546485901\n"
     ]
    }
   ],
   "source": [
    "pscore = p_cnn_model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test accuracy of the basic CNN model:',pscore[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overfitting could clearly be observed here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimized previously"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten,Dropout\n",
    "from keras.layers import LSTM,Conv2D,BatchNormalization,MaxPooling2D,Reshape\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "epochs = 50\n",
    "cnn_optimizer = keras.optimizers.Adam(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep_timed(X,y,sub_sample,average,noise,t):\n",
    "    \n",
    "    total_X = None\n",
    "    total_y = None\n",
    "    \n",
    "    # Trimming the data (sample,22,1000) -> (sample,22,500)\n",
    "    X = X[:,:,0:t]\n",
    "    \n",
    "    # Maxpooling the data (sample,22,1000) -> (sample,22,500/sub_sample)\n",
    "    X_max = np.max(X.reshape(X.shape[0], X.shape[1], -1, sub_sample), axis=3)\n",
    "\n",
    "    \n",
    "    total_X = X_max\n",
    "    total_y = y\n",
    "    \n",
    "    # Averaging + noise \n",
    "    X_average = np.mean(X.reshape(X.shape[0], X.shape[1], -1, average),axis=3)\n",
    "    X_average = X_average + np.random.normal(0.0, 0.5, X_average.shape)\n",
    "    \n",
    "    total_X = np.vstack((total_X, X_average))\n",
    "    total_y = np.hstack((total_y, y))\n",
    "    \n",
    "    # Subsampling\n",
    "    \n",
    "    for i in range(sub_sample):\n",
    "        \n",
    "        X_subsample = X[:, :, i::sub_sample] + \\\n",
    "                            (np.random.normal(0.0, 0.5, X[:, :,i::sub_sample].shape) if noise else 0.0)\n",
    "            \n",
    "        total_X = np.vstack((total_X, X_subsample))\n",
    "        total_y = np.hstack((total_y, y))\n",
    "        \n",
    "    \n",
    "    return total_X,total_y\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.load(\"X_test.npy\")\n",
    "y_test = np.load(\"y_test.npy\")\n",
    "person_train_valid = np.squeeze(np.load(\"person_train_valid.npy\"))\n",
    "X_train_valid = np.load(\"X_train_valid.npy\")\n",
    "y_train_valid = np.load(\"y_train_valid.npy\")\n",
    "person_test = np.squeeze(np.load(\"person_test.npy\"))\n",
    "\n",
    "\n",
    "y_train_valid -= 769\n",
    "y_test -= 769"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random splitting and reshaping the data\n",
    "# First generating the training and validation indices using random splitting\n",
    "\n",
    "ind_valid = np.random.choice(2115, 375, replace=False)\n",
    "ind_train = np.array(list(set(range(2115)).difference(set(ind_valid))))\n",
    "\n",
    "# Creating the training and validation sets using the generated indices\n",
    "(X_train, X_valid) = X_train_valid[ind_train], X_train_valid[ind_valid] \n",
    "(y_train, y_valid) = y_train_valid[ind_train], y_train_valid[ind_valid]\n",
    "\n",
    "xs_train =[]\n",
    "xs_valid =[]\n",
    "xs_test = []\n",
    "ys_train =[]\n",
    "ys_valid =[]\n",
    "ys_test = []\n",
    "t_list = [200,400,500,600,800,1000]\n",
    "\n",
    "\n",
    "## Preprocessing the dataset with different time\n",
    "for t in t_list:\n",
    "    print(t)\n",
    "    x_train,y_train = data_prep_timed(X_train,y_train,2,2,True,t)\n",
    "    x_valid,y_valid = data_prep_timed(X_valid,y_valid,2,2,True,t)\n",
    "    X_test_prep,y_test_prep = data_prep_timed(X_test,y_test,2,2,True,t)\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "    # Converting the labels to categorical variables for multiclass classification\n",
    "    y_train = to_categorical(y_train, 4)\n",
    "    y_valid = to_categorical(y_valid, 4)\n",
    "    y_test = to_categorical(y_test_prep, 4)\n",
    "    \n",
    "    # Adding width of the segment to be 1\n",
    "    x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
    "    x_valid = x_valid.reshape(x_valid.shape[0], x_valid.shape[1], x_train.shape[2], 1)\n",
    "    x_test = X_test_prep.reshape(X_test_prep.shape[0], X_test_prep.shape[1], X_test_prep.shape[2], 1)\n",
    "    \n",
    "\n",
    "    # Reshaping the training and validation dataset\n",
    "    x_train = np.swapaxes(x_train, 1,3)\n",
    "    x_train = np.swapaxes(x_train, 1,2)\n",
    "    x_valid = np.swapaxes(x_valid, 1,3)\n",
    "    x_valid = np.swapaxes(x_valid, 1,2)\n",
    "    x_test = np.swapaxes(x_test, 1,3)\n",
    "    x_test = np.swapaxes(x_test, 1,2)\n",
    "    \n",
    "    xs_train.append(x_train)\n",
    "    xs_valid.append(x_valid)\n",
    "    xs_test.append(x_test)\n",
    "    ys_train.append(y_train)\n",
    "    ys_valid.append(y_valid)\n",
    "    ys_test.append(y_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not enough memory to store all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random splitting and reshaping the data\n",
    "# First generating the training and validation indices using random splitting\n",
    "\n",
    "ind_valid = np.random.choice(2115, 375, replace=False)\n",
    "ind_train = np.array(list(set(range(2115)).difference(set(ind_valid))))\n",
    "\n",
    "# Creating the training and validation sets using the generated indices\n",
    "(X_train, X_valid) = X_train_valid[ind_train], X_train_valid[ind_valid] \n",
    "(Y_train, Y_valid) = y_train_valid[ind_train], y_train_valid[ind_valid]\n",
    "\n",
    "tscores = []\n",
    "\n",
    "Y_test = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 200\n",
    "## Use same train valid split\n",
    "x_train,y_train = data_prep_timed(X_train,Y_train,2,2,True,t)\n",
    "x_valid,y_valid = data_prep_timed(X_valid,Y_valid,2,2,True,t)\n",
    "X_test_prep,y_test_prep = data_prep_timed(X_test,Y_test,2,2,True,t)\n",
    "\n",
    "# Converting the labels to categorical variables for multiclass classification\n",
    "y_train = to_categorical(y_train, 4)\n",
    "y_valid = to_categorical(y_valid, 4)\n",
    "y_test = to_categorical(y_test_prep, 4)\n",
    "\n",
    "# Adding width of the segment to be 1\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
    "x_valid = x_valid.reshape(x_valid.shape[0], x_valid.shape[1], x_train.shape[2], 1)\n",
    "x_test = X_test_prep.reshape(X_test_prep.shape[0], X_test_prep.shape[1], X_test_prep.shape[2], 1)\n",
    "\n",
    "\n",
    "# Reshaping the training and validation dataset\n",
    "x_train = np.swapaxes(x_train, 1,3)\n",
    "x_train = np.swapaxes(x_train, 1,2)\n",
    "x_valid = np.swapaxes(x_valid, 1,3)\n",
    "x_valid = np.swapaxes(x_valid, 1,2)\n",
    "x_test = np.swapaxes(x_test, 1,3)\n",
    "x_test = np.swapaxes(x_test, 1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_16 (Conv2D)          (None, 100, 1, 25)        5525      \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 34, 1, 25)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_16 (Bat  (None, 34, 1, 25)        100       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 34, 1, 25)         0         \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 34, 1, 50)         12550     \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 12, 1, 50)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_17 (Bat  (None, 12, 1, 50)        200       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 12, 1, 50)         0         \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 12, 1, 100)        50100     \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 4, 1, 100)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_18 (Bat  (None, 4, 1, 100)        400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 4, 1, 100)         0         \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 4, 1, 200)         200200    \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 2, 1, 200)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_19 (Bat  (None, 2, 1, 200)        800       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 2, 1, 200)         0         \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 400)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 4)                 1604      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 271,479\n",
      "Trainable params: 270,729\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Building the CNN model using sequential class\n",
    "t_cnn_model = Sequential()\n",
    "\n",
    "# Conv. block 1\n",
    "t_cnn_model.add(Conv2D(filters=25, kernel_size=(10,1), padding='same', activation='elu', input_shape=x_train.shape[1:4]))\n",
    "t_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same')) # Read the keras documentation\n",
    "t_cnn_model.add(BatchNormalization())\n",
    "t_cnn_model.add(Dropout(0.5))\n",
    "\n",
    "# Conv. block 2\n",
    "t_cnn_model.add(Conv2D(filters=50, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "t_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "t_cnn_model.add(BatchNormalization())\n",
    "t_cnn_model.add(Dropout(0.5))\n",
    "\n",
    "# Conv. block 3\n",
    "t_cnn_model.add(Conv2D(filters=100, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "t_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "t_cnn_model.add(BatchNormalization())\n",
    "t_cnn_model.add(Dropout(0.5))\n",
    "\n",
    "# Conv. block 4\n",
    "t_cnn_model.add(Conv2D(filters=200, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "t_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "t_cnn_model.add(BatchNormalization())\n",
    "t_cnn_model.add(Dropout(0.5))\n",
    "\n",
    "# Output layer with Softmax activation\n",
    "t_cnn_model.add(Flatten()) # Flattens the input\n",
    "t_cnn_model.add(Dense(4, activation='softmax')) # Output FC layer with softmax activation\n",
    "\n",
    "\n",
    "# Printing the model summary\n",
    "t_cnn_model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "109/109 [==============================] - 2s 13ms/step - loss: 2.0168 - accuracy: 0.2920 - val_loss: 1.4028 - val_accuracy: 0.3313\n",
      "Epoch 2/25\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 1.6333 - accuracy: 0.3122 - val_loss: 1.3231 - val_accuracy: 0.3813\n",
      "Epoch 3/25\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 1.4617 - accuracy: 0.3438 - val_loss: 1.3372 - val_accuracy: 0.3640\n",
      "Epoch 4/25\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 1.3470 - accuracy: 0.3838 - val_loss: 1.3264 - val_accuracy: 0.4020\n",
      "Epoch 5/25\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 1.2751 - accuracy: 0.4297 - val_loss: 1.2471 - val_accuracy: 0.4313\n",
      "Epoch 6/25\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 1.2329 - accuracy: 0.4489 - val_loss: 1.1908 - val_accuracy: 0.4680\n",
      "Epoch 7/25\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 1.1906 - accuracy: 0.4743 - val_loss: 1.1484 - val_accuracy: 0.4880\n",
      "Epoch 8/25\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 1.1583 - accuracy: 0.4914 - val_loss: 1.1126 - val_accuracy: 0.5293\n",
      "Epoch 9/25\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 1.1167 - accuracy: 0.5197 - val_loss: 1.2299 - val_accuracy: 0.4420\n",
      "Epoch 10/25\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 1.0970 - accuracy: 0.5346 - val_loss: 1.1579 - val_accuracy: 0.5007\n",
      "Epoch 11/25\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 1.0859 - accuracy: 0.5341 - val_loss: 1.0611 - val_accuracy: 0.5480\n",
      "Epoch 12/25\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 1.0559 - accuracy: 0.5476 - val_loss: 1.1297 - val_accuracy: 0.5033\n",
      "Epoch 13/25\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 1.0290 - accuracy: 0.5618 - val_loss: 1.0812 - val_accuracy: 0.5380\n",
      "Epoch 14/25\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 1.0046 - accuracy: 0.5733 - val_loss: 1.0654 - val_accuracy: 0.5673\n",
      "Epoch 15/25\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 0.9906 - accuracy: 0.5853 - val_loss: 1.0826 - val_accuracy: 0.5507\n",
      "Epoch 16/25\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 0.9693 - accuracy: 0.5977 - val_loss: 1.1567 - val_accuracy: 0.5280\n",
      "Epoch 17/25\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 0.9347 - accuracy: 0.6152 - val_loss: 1.0335 - val_accuracy: 0.5833\n",
      "Epoch 18/25\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 0.9236 - accuracy: 0.6182 - val_loss: 1.0783 - val_accuracy: 0.5707\n",
      "Epoch 19/25\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 0.8970 - accuracy: 0.6254 - val_loss: 1.0786 - val_accuracy: 0.5860\n",
      "Epoch 20/25\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 0.8893 - accuracy: 0.6375 - val_loss: 1.0868 - val_accuracy: 0.5733\n",
      "Epoch 21/25\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 0.8859 - accuracy: 0.6339 - val_loss: 1.1077 - val_accuracy: 0.5433\n",
      "Epoch 22/25\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 0.8733 - accuracy: 0.6418 - val_loss: 1.0028 - val_accuracy: 0.6187\n",
      "Epoch 23/25\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 0.8570 - accuracy: 0.6503 - val_loss: 1.0521 - val_accuracy: 0.5800\n",
      "Epoch 24/25\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 0.8372 - accuracy: 0.6553 - val_loss: 1.0211 - val_accuracy: 0.5927\n",
      "Epoch 25/25\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 0.8087 - accuracy: 0.6682 - val_loss: 1.0117 - val_accuracy: 0.5953\n"
     ]
    }
   ],
   "source": [
    "t_cnn_model.compile(loss='categorical_crossentropy',\n",
    "                 optimizer=cnn_optimizer,\n",
    "                 metrics=['accuracy'])\n",
    "t_cnn_model_results = t_cnn_model.fit(x_train,\n",
    "             y_train,\n",
    "             batch_size=64,\n",
    "             epochs=25,\n",
    "             validation_data=(x_valid, y_valid), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of the basic CNN model: 0.5761851072311401\n"
     ]
    }
   ],
   "source": [
    "tscore = t_cnn_model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test accuracy of the basic CNN model:',tscore[1])\n",
    "tscores.append(tscore[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_24 (Conv2D)          (None, 200, 1, 25)        5525      \n",
      "                                                                 \n",
      " max_pooling2d_24 (MaxPoolin  (None, 67, 1, 25)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_24 (Bat  (None, 67, 1, 25)        100       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 67, 1, 25)         0         \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 67, 1, 50)         12550     \n",
      "                                                                 \n",
      " max_pooling2d_25 (MaxPoolin  (None, 23, 1, 50)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_25 (Bat  (None, 23, 1, 50)        200       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 23, 1, 50)         0         \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 23, 1, 100)        50100     \n",
      "                                                                 \n",
      " max_pooling2d_26 (MaxPoolin  (None, 8, 1, 100)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_26 (Bat  (None, 8, 1, 100)        400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 8, 1, 100)         0         \n",
      "                                                                 \n",
      " conv2d_27 (Conv2D)          (None, 8, 1, 200)         200200    \n",
      "                                                                 \n",
      " max_pooling2d_27 (MaxPoolin  (None, 3, 1, 200)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_27 (Bat  (None, 3, 1, 200)        800       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 3, 1, 200)         0         \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 600)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 4)                 2404      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 272,279\n",
      "Trainable params: 271,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "109/109 [==============================] - 3s 21ms/step - loss: 1.7796 - accuracy: 0.3270 - val_loss: 1.7347 - val_accuracy: 0.3300\n",
      "Epoch 2/25\n",
      "109/109 [==============================] - 2s 19ms/step - loss: 1.3679 - accuracy: 0.3861 - val_loss: 1.2630 - val_accuracy: 0.4113\n",
      "Epoch 3/25\n",
      "109/109 [==============================] - 2s 19ms/step - loss: 1.2663 - accuracy: 0.4388 - val_loss: 1.2073 - val_accuracy: 0.4553\n",
      "Epoch 4/25\n",
      "109/109 [==============================] - 2s 19ms/step - loss: 1.1918 - accuracy: 0.4711 - val_loss: 1.2033 - val_accuracy: 0.4533\n",
      "Epoch 5/25\n",
      "109/109 [==============================] - 2s 19ms/step - loss: 1.1431 - accuracy: 0.4989 - val_loss: 1.1286 - val_accuracy: 0.5360\n",
      "Epoch 6/25\n",
      "109/109 [==============================] - 2s 19ms/step - loss: 1.0820 - accuracy: 0.5417 - val_loss: 1.1096 - val_accuracy: 0.5600\n",
      "Epoch 7/25\n",
      "109/109 [==============================] - 2s 19ms/step - loss: 1.0242 - accuracy: 0.5681 - val_loss: 1.0655 - val_accuracy: 0.5753\n",
      "Epoch 8/25\n",
      "109/109 [==============================] - 2s 19ms/step - loss: 0.9833 - accuracy: 0.5861 - val_loss: 1.0131 - val_accuracy: 0.6107\n",
      "Epoch 9/25\n",
      "109/109 [==============================] - 2s 19ms/step - loss: 0.9348 - accuracy: 0.6121 - val_loss: 0.9703 - val_accuracy: 0.6200\n",
      "Epoch 10/25\n",
      "109/109 [==============================] - 2s 19ms/step - loss: 0.8989 - accuracy: 0.6333 - val_loss: 0.9819 - val_accuracy: 0.6140\n",
      "Epoch 11/25\n",
      "109/109 [==============================] - 2s 19ms/step - loss: 0.8727 - accuracy: 0.6478 - val_loss: 0.9692 - val_accuracy: 0.6127\n",
      "Epoch 12/25\n",
      "109/109 [==============================] - 2s 19ms/step - loss: 0.8094 - accuracy: 0.6691 - val_loss: 0.9498 - val_accuracy: 0.6220\n",
      "Epoch 13/25\n",
      "109/109 [==============================] - 2s 20ms/step - loss: 0.7985 - accuracy: 0.6797 - val_loss: 0.9678 - val_accuracy: 0.6080\n",
      "Epoch 14/25\n",
      "109/109 [==============================] - 2s 20ms/step - loss: 0.7665 - accuracy: 0.6907 - val_loss: 0.8729 - val_accuracy: 0.6440\n",
      "Epoch 15/25\n",
      "109/109 [==============================] - 2s 20ms/step - loss: 0.7391 - accuracy: 0.7011 - val_loss: 0.8784 - val_accuracy: 0.6760\n",
      "Epoch 16/25\n",
      "109/109 [==============================] - 2s 20ms/step - loss: 0.7182 - accuracy: 0.7126 - val_loss: 0.8903 - val_accuracy: 0.6740\n",
      "Epoch 17/25\n",
      "109/109 [==============================] - 2s 20ms/step - loss: 0.6846 - accuracy: 0.7318 - val_loss: 0.8744 - val_accuracy: 0.6347\n",
      "Epoch 18/25\n",
      "109/109 [==============================] - 2s 19ms/step - loss: 0.6620 - accuracy: 0.7371 - val_loss: 0.8983 - val_accuracy: 0.6493\n",
      "Epoch 19/25\n",
      "109/109 [==============================] - 2s 19ms/step - loss: 0.6445 - accuracy: 0.7478 - val_loss: 0.9280 - val_accuracy: 0.6400\n",
      "Epoch 20/25\n",
      "109/109 [==============================] - 2s 19ms/step - loss: 0.6343 - accuracy: 0.7550 - val_loss: 0.8722 - val_accuracy: 0.6493\n",
      "Epoch 21/25\n",
      "109/109 [==============================] - 2s 19ms/step - loss: 0.6031 - accuracy: 0.7621 - val_loss: 0.8721 - val_accuracy: 0.6580\n",
      "Epoch 22/25\n",
      "109/109 [==============================] - 2s 19ms/step - loss: 0.6004 - accuracy: 0.7658 - val_loss: 0.8433 - val_accuracy: 0.6680\n",
      "Epoch 23/25\n",
      "109/109 [==============================] - 2s 20ms/step - loss: 0.5933 - accuracy: 0.7621 - val_loss: 0.8889 - val_accuracy: 0.6600\n",
      "Epoch 24/25\n",
      "109/109 [==============================] - 2s 20ms/step - loss: 0.5504 - accuracy: 0.7891 - val_loss: 0.8160 - val_accuracy: 0.7053\n",
      "Epoch 25/25\n",
      "109/109 [==============================] - 2s 20ms/step - loss: 0.5619 - accuracy: 0.7836 - val_loss: 0.8603 - val_accuracy: 0.6860\n",
      "Test accuracy of the basic CNN model: 0.6574491858482361\n"
     ]
    }
   ],
   "source": [
    "t = 400\n",
    "## Use same train valid split\n",
    "x_train,y_train = data_prep_timed(X_train,Y_train,2,2,True,t)\n",
    "x_valid,y_valid = data_prep_timed(X_valid,Y_valid,2,2,True,t)\n",
    "X_test_prep,y_test_prep = data_prep_timed(X_test,Y_test,2,2,True,t)\n",
    "\n",
    "# Converting the labels to categorical variables for multiclass classification\n",
    "y_train = to_categorical(y_train, 4)\n",
    "y_valid = to_categorical(y_valid, 4)\n",
    "y_test = to_categorical(y_test_prep, 4)\n",
    "\n",
    "# Adding width of the segment to be 1\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
    "x_valid = x_valid.reshape(x_valid.shape[0], x_valid.shape[1], x_train.shape[2], 1)\n",
    "x_test = X_test_prep.reshape(X_test_prep.shape[0], X_test_prep.shape[1], X_test_prep.shape[2], 1)\n",
    "\n",
    "\n",
    "# Reshaping the training and validation dataset\n",
    "x_train = np.swapaxes(x_train, 1,3)\n",
    "x_train = np.swapaxes(x_train, 1,2)\n",
    "x_valid = np.swapaxes(x_valid, 1,3)\n",
    "x_valid = np.swapaxes(x_valid, 1,2)\n",
    "x_test = np.swapaxes(x_test, 1,3)\n",
    "x_test = np.swapaxes(x_test, 1,2)\n",
    "\n",
    "# Building the CNN model using sequential class\n",
    "t_cnn_model = Sequential()\n",
    "\n",
    "# Conv. block 1\n",
    "t_cnn_model.add(Conv2D(filters=25, kernel_size=(10,1), padding='same', activation='elu', input_shape=x_train.shape[1:4]))\n",
    "t_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same')) # Read the keras documentation\n",
    "t_cnn_model.add(BatchNormalization())\n",
    "t_cnn_model.add(Dropout(0.5))\n",
    "\n",
    "# Conv. block 2\n",
    "t_cnn_model.add(Conv2D(filters=50, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "t_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "t_cnn_model.add(BatchNormalization())\n",
    "t_cnn_model.add(Dropout(0.5))\n",
    "\n",
    "# Conv. block 3\n",
    "t_cnn_model.add(Conv2D(filters=100, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "t_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "t_cnn_model.add(BatchNormalization())\n",
    "t_cnn_model.add(Dropout(0.5))\n",
    "\n",
    "# Conv. block 4\n",
    "t_cnn_model.add(Conv2D(filters=200, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "t_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "t_cnn_model.add(BatchNormalization())\n",
    "t_cnn_model.add(Dropout(0.5))\n",
    "\n",
    "# Output layer with Softmax activation\n",
    "t_cnn_model.add(Flatten()) # Flattens the input\n",
    "t_cnn_model.add(Dense(4, activation='softmax')) # Output FC layer with softmax activation\n",
    "\n",
    "\n",
    "# Printing the model summary\n",
    "t_cnn_model.summary()\n",
    "\n",
    "t_cnn_model.compile(loss='categorical_crossentropy',\n",
    "                 optimizer=cnn_optimizer,\n",
    "                 metrics=['accuracy'])\n",
    "t_cnn_model_results = t_cnn_model.fit(x_train,\n",
    "             y_train,\n",
    "             batch_size=64,\n",
    "             epochs=25,\n",
    "             validation_data=(x_valid, y_valid), verbose=True)\n",
    "\n",
    "tscore = t_cnn_model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test accuracy of the basic CNN model:',tscore[1])\n",
    "tscores.append(tscore[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_28 (Conv2D)          (None, 250, 1, 25)        5525      \n",
      "                                                                 \n",
      " max_pooling2d_28 (MaxPoolin  (None, 84, 1, 25)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_28 (Bat  (None, 84, 1, 25)        100       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, 84, 1, 25)         0         \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          (None, 84, 1, 50)         12550     \n",
      "                                                                 \n",
      " max_pooling2d_29 (MaxPoolin  (None, 28, 1, 50)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_29 (Bat  (None, 28, 1, 50)        200       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 28, 1, 50)         0         \n",
      "                                                                 \n",
      " conv2d_30 (Conv2D)          (None, 28, 1, 100)        50100     \n",
      "                                                                 \n",
      " max_pooling2d_30 (MaxPoolin  (None, 10, 1, 100)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_30 (Bat  (None, 10, 1, 100)       400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_30 (Dropout)        (None, 10, 1, 100)        0         \n",
      "                                                                 \n",
      " conv2d_31 (Conv2D)          (None, 10, 1, 200)        200200    \n",
      "                                                                 \n",
      " max_pooling2d_31 (MaxPoolin  (None, 4, 1, 200)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_31 (Bat  (None, 4, 1, 200)        800       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_31 (Dropout)        (None, 4, 1, 200)         0         \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 800)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 4)                 3204      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 273,079\n",
      "Trainable params: 272,329\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 1.7982 - accuracy: 0.3305 - val_loss: 1.7946 - val_accuracy: 0.3367\n",
      "Epoch 2/25\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 1.3885 - accuracy: 0.3970 - val_loss: 1.2399 - val_accuracy: 0.4573\n",
      "Epoch 3/25\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 1.2450 - accuracy: 0.4563 - val_loss: 1.1464 - val_accuracy: 0.5040\n",
      "Epoch 4/25\n",
      "109/109 [==============================] - 3s 23ms/step - loss: 1.1304 - accuracy: 0.5210 - val_loss: 1.0900 - val_accuracy: 0.5627\n",
      "Epoch 5/25\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 1.0872 - accuracy: 0.5460 - val_loss: 1.1102 - val_accuracy: 0.5327\n",
      "Epoch 6/25\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 1.0228 - accuracy: 0.5751 - val_loss: 1.0131 - val_accuracy: 0.5800\n",
      "Epoch 7/25\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.9647 - accuracy: 0.6068 - val_loss: 1.0590 - val_accuracy: 0.5873\n",
      "Epoch 8/25\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.9234 - accuracy: 0.6237 - val_loss: 0.9891 - val_accuracy: 0.6040\n",
      "Epoch 9/25\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.8699 - accuracy: 0.6550 - val_loss: 0.9881 - val_accuracy: 0.5907\n",
      "Epoch 10/25\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.8434 - accuracy: 0.6598 - val_loss: 1.0033 - val_accuracy: 0.5853\n",
      "Epoch 11/25\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.7997 - accuracy: 0.6800 - val_loss: 0.9442 - val_accuracy: 0.6293\n",
      "Epoch 12/25\n",
      "109/109 [==============================] - 3s 23ms/step - loss: 0.7677 - accuracy: 0.6935 - val_loss: 0.9273 - val_accuracy: 0.6427\n",
      "Epoch 13/25\n",
      "109/109 [==============================] - 3s 23ms/step - loss: 0.7292 - accuracy: 0.7078 - val_loss: 0.9350 - val_accuracy: 0.6200\n",
      "Epoch 14/25\n",
      "109/109 [==============================] - 2s 22ms/step - loss: 0.7143 - accuracy: 0.7226 - val_loss: 0.9387 - val_accuracy: 0.6120\n",
      "Epoch 15/25\n",
      "109/109 [==============================] - 2s 23ms/step - loss: 0.6802 - accuracy: 0.7315 - val_loss: 0.9518 - val_accuracy: 0.6160\n",
      "Epoch 16/25\n",
      "109/109 [==============================] - 2s 22ms/step - loss: 0.6610 - accuracy: 0.7411 - val_loss: 0.9035 - val_accuracy: 0.6240\n",
      "Epoch 17/25\n",
      "109/109 [==============================] - 3s 23ms/step - loss: 0.6351 - accuracy: 0.7536 - val_loss: 0.9234 - val_accuracy: 0.6220\n",
      "Epoch 18/25\n",
      "109/109 [==============================] - 2s 23ms/step - loss: 0.6250 - accuracy: 0.7552 - val_loss: 0.9159 - val_accuracy: 0.6273\n",
      "Epoch 19/25\n",
      "109/109 [==============================] - 3s 23ms/step - loss: 0.6011 - accuracy: 0.7672 - val_loss: 0.9076 - val_accuracy: 0.6433\n",
      "Epoch 20/25\n",
      "109/109 [==============================] - 3s 23ms/step - loss: 0.5827 - accuracy: 0.7704 - val_loss: 0.9630 - val_accuracy: 0.6220\n",
      "Epoch 21/25\n",
      "109/109 [==============================] - 2s 22ms/step - loss: 0.5628 - accuracy: 0.7838 - val_loss: 0.9299 - val_accuracy: 0.6413\n",
      "Epoch 22/25\n",
      "109/109 [==============================] - 2s 23ms/step - loss: 0.5431 - accuracy: 0.7897 - val_loss: 0.8772 - val_accuracy: 0.6560\n",
      "Epoch 23/25\n",
      "109/109 [==============================] - 2s 22ms/step - loss: 0.5193 - accuracy: 0.7963 - val_loss: 0.8885 - val_accuracy: 0.6560\n",
      "Epoch 24/25\n",
      "109/109 [==============================] - 2s 23ms/step - loss: 0.5082 - accuracy: 0.8019 - val_loss: 0.9134 - val_accuracy: 0.6520\n",
      "Epoch 25/25\n",
      "109/109 [==============================] - 2s 22ms/step - loss: 0.4964 - accuracy: 0.8083 - val_loss: 0.9169 - val_accuracy: 0.6540\n",
      "Test accuracy of the basic CNN model: 0.6625282168388367\n"
     ]
    }
   ],
   "source": [
    "t = 500\n",
    "## Use same train valid split\n",
    "x_train,y_train = data_prep_timed(X_train,Y_train,2,2,True,t)\n",
    "x_valid,y_valid = data_prep_timed(X_valid,Y_valid,2,2,True,t)\n",
    "X_test_prep,y_test_prep = data_prep_timed(X_test,Y_test,2,2,True,t)\n",
    "\n",
    "# Converting the labels to categorical variables for multiclass classification\n",
    "y_train = to_categorical(y_train, 4)\n",
    "y_valid = to_categorical(y_valid, 4)\n",
    "y_test = to_categorical(y_test_prep, 4)\n",
    "\n",
    "# Adding width of the segment to be 1\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
    "x_valid = x_valid.reshape(x_valid.shape[0], x_valid.shape[1], x_train.shape[2], 1)\n",
    "x_test = X_test_prep.reshape(X_test_prep.shape[0], X_test_prep.shape[1], X_test_prep.shape[2], 1)\n",
    "\n",
    "\n",
    "# Reshaping the training and validation dataset\n",
    "x_train = np.swapaxes(x_train, 1,3)\n",
    "x_train = np.swapaxes(x_train, 1,2)\n",
    "x_valid = np.swapaxes(x_valid, 1,3)\n",
    "x_valid = np.swapaxes(x_valid, 1,2)\n",
    "x_test = np.swapaxes(x_test, 1,3)\n",
    "x_test = np.swapaxes(x_test, 1,2)\n",
    "\n",
    "# Building the CNN model using sequential class\n",
    "t_cnn_model = Sequential()\n",
    "\n",
    "# Conv. block 1\n",
    "t_cnn_model.add(Conv2D(filters=25, kernel_size=(10,1), padding='same', activation='elu', input_shape=x_train.shape[1:4]))\n",
    "t_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same')) # Read the keras documentation\n",
    "t_cnn_model.add(BatchNormalization())\n",
    "t_cnn_model.add(Dropout(0.5))\n",
    "\n",
    "# Conv. block 2\n",
    "t_cnn_model.add(Conv2D(filters=50, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "t_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "t_cnn_model.add(BatchNormalization())\n",
    "t_cnn_model.add(Dropout(0.5))\n",
    "\n",
    "# Conv. block 3\n",
    "t_cnn_model.add(Conv2D(filters=100, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "t_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "t_cnn_model.add(BatchNormalization())\n",
    "t_cnn_model.add(Dropout(0.5))\n",
    "\n",
    "# Conv. block 4\n",
    "t_cnn_model.add(Conv2D(filters=200, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "t_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "t_cnn_model.add(BatchNormalization())\n",
    "t_cnn_model.add(Dropout(0.5))\n",
    "\n",
    "# Output layer with Softmax activation\n",
    "t_cnn_model.add(Flatten()) # Flattens the input\n",
    "t_cnn_model.add(Dense(4, activation='softmax')) # Output FC layer with softmax activation\n",
    "\n",
    "\n",
    "# Printing the model summary\n",
    "t_cnn_model.summary()\n",
    "\n",
    "t_cnn_model.compile(loss='categorical_crossentropy',\n",
    "                 optimizer=cnn_optimizer,\n",
    "                 metrics=['accuracy'])\n",
    "t_cnn_model_results = t_cnn_model.fit(x_train,\n",
    "             y_train,\n",
    "             batch_size=64,\n",
    "             epochs=25,\n",
    "             validation_data=(x_valid, y_valid), verbose=True)\n",
    "\n",
    "tscore = t_cnn_model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test accuracy of the basic CNN model:',tscore[1])\n",
    "tscores.append(tscore[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_32 (Conv2D)          (None, 300, 1, 25)        5525      \n",
      "                                                                 \n",
      " max_pooling2d_32 (MaxPoolin  (None, 100, 1, 25)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_32 (Bat  (None, 100, 1, 25)       100       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_32 (Dropout)        (None, 100, 1, 25)        0         \n",
      "                                                                 \n",
      " conv2d_33 (Conv2D)          (None, 100, 1, 50)        12550     \n",
      "                                                                 \n",
      " max_pooling2d_33 (MaxPoolin  (None, 34, 1, 50)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_33 (Bat  (None, 34, 1, 50)        200       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_33 (Dropout)        (None, 34, 1, 50)         0         \n",
      "                                                                 \n",
      " conv2d_34 (Conv2D)          (None, 34, 1, 100)        50100     \n",
      "                                                                 \n",
      " max_pooling2d_34 (MaxPoolin  (None, 12, 1, 100)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_34 (Bat  (None, 12, 1, 100)       400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_34 (Dropout)        (None, 12, 1, 100)        0         \n",
      "                                                                 \n",
      " conv2d_35 (Conv2D)          (None, 12, 1, 200)        200200    \n",
      "                                                                 \n",
      " max_pooling2d_35 (MaxPoolin  (None, 4, 1, 200)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_35 (Bat  (None, 4, 1, 200)        800       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 4, 1, 200)         0         \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 800)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 4)                 3204      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 273,079\n",
      "Trainable params: 272,329\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "109/109 [==============================] - 4s 28ms/step - loss: 1.8278 - accuracy: 0.3254 - val_loss: 1.5506 - val_accuracy: 0.3347\n",
      "Epoch 2/25\n",
      "109/109 [==============================] - 3s 27ms/step - loss: 1.3947 - accuracy: 0.3819 - val_loss: 1.2541 - val_accuracy: 0.4327\n",
      "Epoch 3/25\n",
      "109/109 [==============================] - 3s 26ms/step - loss: 1.2372 - accuracy: 0.4586 - val_loss: 1.1856 - val_accuracy: 0.4747\n",
      "Epoch 4/25\n",
      "109/109 [==============================] - 3s 26ms/step - loss: 1.1437 - accuracy: 0.5180 - val_loss: 1.1544 - val_accuracy: 0.4827\n",
      "Epoch 5/25\n",
      "109/109 [==============================] - 3s 26ms/step - loss: 1.0728 - accuracy: 0.5491 - val_loss: 1.0427 - val_accuracy: 0.5613\n",
      "Epoch 6/25\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 1.0242 - accuracy: 0.5754 - val_loss: 1.0498 - val_accuracy: 0.5400\n",
      "Epoch 7/25\n",
      "109/109 [==============================] - 3s 26ms/step - loss: 0.9592 - accuracy: 0.6056 - val_loss: 0.9905 - val_accuracy: 0.5820\n",
      "Epoch 8/25\n",
      "109/109 [==============================] - 3s 26ms/step - loss: 0.8902 - accuracy: 0.6365 - val_loss: 1.0019 - val_accuracy: 0.5693\n",
      "Epoch 9/25\n",
      "109/109 [==============================] - 3s 26ms/step - loss: 0.8714 - accuracy: 0.6411 - val_loss: 0.9696 - val_accuracy: 0.6147\n",
      "Epoch 10/25\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.8199 - accuracy: 0.6733 - val_loss: 0.9529 - val_accuracy: 0.6093\n",
      "Epoch 11/25\n",
      "109/109 [==============================] - 3s 26ms/step - loss: 0.7896 - accuracy: 0.6892 - val_loss: 0.9677 - val_accuracy: 0.5967\n",
      "Epoch 12/25\n",
      "109/109 [==============================] - 3s 26ms/step - loss: 0.7661 - accuracy: 0.6924 - val_loss: 0.9814 - val_accuracy: 0.6107\n",
      "Epoch 13/25\n",
      "109/109 [==============================] - 3s 26ms/step - loss: 0.7164 - accuracy: 0.7185 - val_loss: 0.9337 - val_accuracy: 0.6340\n",
      "Epoch 14/25\n",
      "109/109 [==============================] - 3s 27ms/step - loss: 0.6931 - accuracy: 0.7253 - val_loss: 0.9155 - val_accuracy: 0.6420\n",
      "Epoch 15/25\n",
      "109/109 [==============================] - 3s 27ms/step - loss: 0.6749 - accuracy: 0.7378 - val_loss: 0.8985 - val_accuracy: 0.6273\n",
      "Epoch 16/25\n",
      "109/109 [==============================] - 3s 27ms/step - loss: 0.6424 - accuracy: 0.7460 - val_loss: 0.9267 - val_accuracy: 0.6267\n",
      "Epoch 17/25\n",
      "109/109 [==============================] - 3s 27ms/step - loss: 0.6285 - accuracy: 0.7493 - val_loss: 0.9178 - val_accuracy: 0.6340\n",
      "Epoch 18/25\n",
      "109/109 [==============================] - 3s 27ms/step - loss: 0.6031 - accuracy: 0.7586 - val_loss: 0.9468 - val_accuracy: 0.6353\n",
      "Epoch 19/25\n",
      "109/109 [==============================] - 3s 27ms/step - loss: 0.5750 - accuracy: 0.7772 - val_loss: 0.9127 - val_accuracy: 0.6347\n",
      "Epoch 20/25\n",
      "109/109 [==============================] - 3s 27ms/step - loss: 0.5428 - accuracy: 0.7920 - val_loss: 0.9165 - val_accuracy: 0.6507\n",
      "Epoch 21/25\n",
      "109/109 [==============================] - 3s 26ms/step - loss: 0.5384 - accuracy: 0.7930 - val_loss: 0.9107 - val_accuracy: 0.6473\n",
      "Epoch 22/25\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.5062 - accuracy: 0.8083 - val_loss: 0.9269 - val_accuracy: 0.6667\n",
      "Epoch 23/25\n",
      "109/109 [==============================] - 3s 26ms/step - loss: 0.4971 - accuracy: 0.8118 - val_loss: 0.9343 - val_accuracy: 0.6527\n",
      "Epoch 24/25\n",
      "109/109 [==============================] - 3s 26ms/step - loss: 0.4793 - accuracy: 0.8187 - val_loss: 0.9230 - val_accuracy: 0.6527\n",
      "Epoch 25/25\n",
      "109/109 [==============================] - 3s 26ms/step - loss: 0.4652 - accuracy: 0.8250 - val_loss: 0.9199 - val_accuracy: 0.6713\n",
      "Test accuracy of the basic CNN model: 0.6551918983459473\n"
     ]
    }
   ],
   "source": [
    "t = 600\n",
    "## Use same train valid split\n",
    "x_train,y_train = data_prep_timed(X_train,Y_train,2,2,True,t)\n",
    "x_valid,y_valid = data_prep_timed(X_valid,Y_valid,2,2,True,t)\n",
    "X_test_prep,y_test_prep = data_prep_timed(X_test,Y_test,2,2,True,t)\n",
    "\n",
    "# Converting the labels to categorical variables for multiclass classification\n",
    "y_train = to_categorical(y_train, 4)\n",
    "y_valid = to_categorical(y_valid, 4)\n",
    "y_test = to_categorical(y_test_prep, 4)\n",
    "\n",
    "# Adding width of the segment to be 1\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
    "x_valid = x_valid.reshape(x_valid.shape[0], x_valid.shape[1], x_train.shape[2], 1)\n",
    "x_test = X_test_prep.reshape(X_test_prep.shape[0], X_test_prep.shape[1], X_test_prep.shape[2], 1)\n",
    "\n",
    "\n",
    "# Reshaping the training and validation dataset\n",
    "x_train = np.swapaxes(x_train, 1,3)\n",
    "x_train = np.swapaxes(x_train, 1,2)\n",
    "x_valid = np.swapaxes(x_valid, 1,3)\n",
    "x_valid = np.swapaxes(x_valid, 1,2)\n",
    "x_test = np.swapaxes(x_test, 1,3)\n",
    "x_test = np.swapaxes(x_test, 1,2)\n",
    "\n",
    "# Building the CNN model using sequential class\n",
    "t_cnn_model = Sequential()\n",
    "\n",
    "# Conv. block 1\n",
    "t_cnn_model.add(Conv2D(filters=25, kernel_size=(10,1), padding='same', activation='elu', input_shape=x_train.shape[1:4]))\n",
    "t_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same')) # Read the keras documentation\n",
    "t_cnn_model.add(BatchNormalization())\n",
    "t_cnn_model.add(Dropout(0.5))\n",
    "\n",
    "# Conv. block 2\n",
    "t_cnn_model.add(Conv2D(filters=50, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "t_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "t_cnn_model.add(BatchNormalization())\n",
    "t_cnn_model.add(Dropout(0.5))\n",
    "\n",
    "# Conv. block 3\n",
    "t_cnn_model.add(Conv2D(filters=100, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "t_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "t_cnn_model.add(BatchNormalization())\n",
    "t_cnn_model.add(Dropout(0.5))\n",
    "\n",
    "# Conv. block 4\n",
    "t_cnn_model.add(Conv2D(filters=200, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "t_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "t_cnn_model.add(BatchNormalization())\n",
    "t_cnn_model.add(Dropout(0.5))\n",
    "\n",
    "# Output layer with Softmax activation\n",
    "t_cnn_model.add(Flatten()) # Flattens the input\n",
    "t_cnn_model.add(Dense(4, activation='softmax')) # Output FC layer with softmax activation\n",
    "\n",
    "\n",
    "# Printing the model summary\n",
    "t_cnn_model.summary()\n",
    "\n",
    "t_cnn_model.compile(loss='categorical_crossentropy',\n",
    "                 optimizer=cnn_optimizer,\n",
    "                 metrics=['accuracy'])\n",
    "t_cnn_model_results = t_cnn_model.fit(x_train,\n",
    "             y_train,\n",
    "             batch_size=64,\n",
    "             epochs=25,\n",
    "             validation_data=(x_valid, y_valid), verbose=True)\n",
    "\n",
    "tscore = t_cnn_model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test accuracy of the basic CNN model:',tscore[1])\n",
    "tscores.append(tscore[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_36 (Conv2D)          (None, 400, 1, 25)        5525      \n",
      "                                                                 \n",
      " max_pooling2d_36 (MaxPoolin  (None, 134, 1, 25)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_36 (Bat  (None, 134, 1, 25)       100       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_36 (Dropout)        (None, 134, 1, 25)        0         \n",
      "                                                                 \n",
      " conv2d_37 (Conv2D)          (None, 134, 1, 50)        12550     \n",
      "                                                                 \n",
      " max_pooling2d_37 (MaxPoolin  (None, 45, 1, 50)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_37 (Bat  (None, 45, 1, 50)        200       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        (None, 45, 1, 50)         0         \n",
      "                                                                 \n",
      " conv2d_38 (Conv2D)          (None, 45, 1, 100)        50100     \n",
      "                                                                 \n",
      " max_pooling2d_38 (MaxPoolin  (None, 15, 1, 100)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_38 (Bat  (None, 15, 1, 100)       400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_38 (Dropout)        (None, 15, 1, 100)        0         \n",
      "                                                                 \n",
      " conv2d_39 (Conv2D)          (None, 15, 1, 200)        200200    \n",
      "                                                                 \n",
      " max_pooling2d_39 (MaxPoolin  (None, 5, 1, 200)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_39 (Bat  (None, 5, 1, 200)        800       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_39 (Dropout)        (None, 5, 1, 200)         0         \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 4)                 4004      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 273,879\n",
      "Trainable params: 273,129\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "109/109 [==============================] - 4s 35ms/step - loss: 1.9264 - accuracy: 0.3256 - val_loss: 1.9517 - val_accuracy: 0.2993\n",
      "Epoch 2/25\n",
      "109/109 [==============================] - 4s 33ms/step - loss: 1.4238 - accuracy: 0.3688 - val_loss: 1.3388 - val_accuracy: 0.3747\n",
      "Epoch 3/25\n",
      "109/109 [==============================] - 4s 33ms/step - loss: 1.2714 - accuracy: 0.4414 - val_loss: 1.2514 - val_accuracy: 0.3907\n",
      "Epoch 4/25\n",
      "109/109 [==============================] - 4s 33ms/step - loss: 1.2088 - accuracy: 0.4740 - val_loss: 1.2292 - val_accuracy: 0.4340\n",
      "Epoch 5/25\n",
      "109/109 [==============================] - 4s 34ms/step - loss: 1.1466 - accuracy: 0.5026 - val_loss: 1.1760 - val_accuracy: 0.4987\n",
      "Epoch 6/25\n",
      "109/109 [==============================] - 4s 33ms/step - loss: 1.0936 - accuracy: 0.5272 - val_loss: 1.1414 - val_accuracy: 0.5240\n",
      "Epoch 7/25\n",
      "109/109 [==============================] - 4s 33ms/step - loss: 1.0339 - accuracy: 0.5664 - val_loss: 1.1392 - val_accuracy: 0.4880\n",
      "Epoch 8/25\n",
      "109/109 [==============================] - 4s 33ms/step - loss: 0.9891 - accuracy: 0.5932 - val_loss: 1.1160 - val_accuracy: 0.5327\n",
      "Epoch 9/25\n",
      "109/109 [==============================] - 4s 33ms/step - loss: 0.9407 - accuracy: 0.6099 - val_loss: 1.0950 - val_accuracy: 0.5473\n",
      "Epoch 10/25\n",
      "109/109 [==============================] - 4s 32ms/step - loss: 0.8782 - accuracy: 0.6414 - val_loss: 1.0752 - val_accuracy: 0.5513\n",
      "Epoch 11/25\n",
      "109/109 [==============================] - 4s 33ms/step - loss: 0.8345 - accuracy: 0.6616 - val_loss: 1.0993 - val_accuracy: 0.5340\n",
      "Epoch 12/25\n",
      "109/109 [==============================] - 4s 32ms/step - loss: 0.7993 - accuracy: 0.6783 - val_loss: 1.0895 - val_accuracy: 0.5420\n",
      "Epoch 13/25\n",
      "109/109 [==============================] - 4s 32ms/step - loss: 0.7735 - accuracy: 0.6858 - val_loss: 1.1223 - val_accuracy: 0.5473\n",
      "Epoch 14/25\n",
      "109/109 [==============================] - 4s 32ms/step - loss: 0.7385 - accuracy: 0.7040 - val_loss: 1.0683 - val_accuracy: 0.5800\n",
      "Epoch 15/25\n",
      "109/109 [==============================] - 3s 32ms/step - loss: 0.7257 - accuracy: 0.7106 - val_loss: 1.0725 - val_accuracy: 0.5733\n",
      "Epoch 16/25\n",
      "109/109 [==============================] - 4s 32ms/step - loss: 0.6794 - accuracy: 0.7292 - val_loss: 1.0648 - val_accuracy: 0.5713\n",
      "Epoch 17/25\n",
      "109/109 [==============================] - 4s 32ms/step - loss: 0.6475 - accuracy: 0.7464 - val_loss: 1.0692 - val_accuracy: 0.5753\n",
      "Epoch 18/25\n",
      "109/109 [==============================] - 4s 32ms/step - loss: 0.6130 - accuracy: 0.7536 - val_loss: 1.1065 - val_accuracy: 0.5780\n",
      "Epoch 19/25\n",
      "109/109 [==============================] - 4s 32ms/step - loss: 0.5825 - accuracy: 0.7733 - val_loss: 1.0722 - val_accuracy: 0.5833\n",
      "Epoch 20/25\n",
      "109/109 [==============================] - 3s 32ms/step - loss: 0.5638 - accuracy: 0.7795 - val_loss: 1.0378 - val_accuracy: 0.5980\n",
      "Epoch 21/25\n",
      "109/109 [==============================] - 4s 32ms/step - loss: 0.5400 - accuracy: 0.7901 - val_loss: 1.0782 - val_accuracy: 0.5900\n",
      "Epoch 22/25\n",
      "109/109 [==============================] - 4s 33ms/step - loss: 0.5262 - accuracy: 0.7931 - val_loss: 1.0773 - val_accuracy: 0.6100\n",
      "Epoch 23/25\n",
      "109/109 [==============================] - 4s 32ms/step - loss: 0.4972 - accuracy: 0.8050 - val_loss: 1.0760 - val_accuracy: 0.6080\n",
      "Epoch 24/25\n",
      "109/109 [==============================] - 4s 32ms/step - loss: 0.4833 - accuracy: 0.8099 - val_loss: 1.0546 - val_accuracy: 0.6433\n",
      "Epoch 25/25\n",
      "109/109 [==============================] - 4s 33ms/step - loss: 0.4731 - accuracy: 0.8188 - val_loss: 1.0532 - val_accuracy: 0.6260\n",
      "Test accuracy of the basic CNN model: 0.6055305004119873\n"
     ]
    }
   ],
   "source": [
    "t = 800\n",
    "## Use same train valid split\n",
    "x_train,y_train = data_prep_timed(X_train,Y_train,2,2,True,t)\n",
    "x_valid,y_valid = data_prep_timed(X_valid,Y_valid,2,2,True,t)\n",
    "X_test_prep,y_test_prep = data_prep_timed(X_test,Y_test,2,2,True,t)\n",
    "\n",
    "# Converting the labels to categorical variables for multiclass classification\n",
    "y_train = to_categorical(y_train, 4)\n",
    "y_valid = to_categorical(y_valid, 4)\n",
    "y_test = to_categorical(y_test_prep, 4)\n",
    "\n",
    "# Adding width of the segment to be 1\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
    "x_valid = x_valid.reshape(x_valid.shape[0], x_valid.shape[1], x_train.shape[2], 1)\n",
    "x_test = X_test_prep.reshape(X_test_prep.shape[0], X_test_prep.shape[1], X_test_prep.shape[2], 1)\n",
    "\n",
    "\n",
    "# Reshaping the training and validation dataset\n",
    "x_train = np.swapaxes(x_train, 1,3)\n",
    "x_train = np.swapaxes(x_train, 1,2)\n",
    "x_valid = np.swapaxes(x_valid, 1,3)\n",
    "x_valid = np.swapaxes(x_valid, 1,2)\n",
    "x_test = np.swapaxes(x_test, 1,3)\n",
    "x_test = np.swapaxes(x_test, 1,2)\n",
    "\n",
    "# Building the CNN model using sequential class\n",
    "t_cnn_model = Sequential()\n",
    "\n",
    "# Conv. block 1\n",
    "t_cnn_model.add(Conv2D(filters=25, kernel_size=(10,1), padding='same', activation='elu', input_shape=x_train.shape[1:4]))\n",
    "t_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same')) # Read the keras documentation\n",
    "t_cnn_model.add(BatchNormalization())\n",
    "t_cnn_model.add(Dropout(0.5))\n",
    "\n",
    "# Conv. block 2\n",
    "t_cnn_model.add(Conv2D(filters=50, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "t_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "t_cnn_model.add(BatchNormalization())\n",
    "t_cnn_model.add(Dropout(0.5))\n",
    "\n",
    "# Conv. block 3\n",
    "t_cnn_model.add(Conv2D(filters=100, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "t_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "t_cnn_model.add(BatchNormalization())\n",
    "t_cnn_model.add(Dropout(0.5))\n",
    "\n",
    "# Conv. block 4\n",
    "t_cnn_model.add(Conv2D(filters=200, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "t_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "t_cnn_model.add(BatchNormalization())\n",
    "t_cnn_model.add(Dropout(0.5))\n",
    "\n",
    "# Output layer with Softmax activation\n",
    "t_cnn_model.add(Flatten()) # Flattens the input\n",
    "t_cnn_model.add(Dense(4, activation='softmax')) # Output FC layer with softmax activation\n",
    "\n",
    "\n",
    "# Printing the model summary\n",
    "t_cnn_model.summary()\n",
    "\n",
    "t_cnn_model.compile(loss='categorical_crossentropy',\n",
    "                 optimizer=cnn_optimizer,\n",
    "                 metrics=['accuracy'])\n",
    "t_cnn_model_results = t_cnn_model.fit(x_train,\n",
    "             y_train,\n",
    "             batch_size=64,\n",
    "             epochs=25,\n",
    "             validation_data=(x_valid, y_valid), verbose=True)\n",
    "\n",
    "tscore = t_cnn_model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test accuracy of the basic CNN model:',tscore[1])\n",
    "tscores.append(tscore[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_40 (Conv2D)          (None, 500, 1, 25)        5525      \n",
      "                                                                 \n",
      " max_pooling2d_40 (MaxPoolin  (None, 167, 1, 25)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_40 (Bat  (None, 167, 1, 25)       100       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_40 (Dropout)        (None, 167, 1, 25)        0         \n",
      "                                                                 \n",
      " conv2d_41 (Conv2D)          (None, 167, 1, 50)        12550     \n",
      "                                                                 \n",
      " max_pooling2d_41 (MaxPoolin  (None, 56, 1, 50)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_41 (Bat  (None, 56, 1, 50)        200       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_41 (Dropout)        (None, 56, 1, 50)         0         \n",
      "                                                                 \n",
      " conv2d_42 (Conv2D)          (None, 56, 1, 100)        50100     \n",
      "                                                                 \n",
      " max_pooling2d_42 (MaxPoolin  (None, 19, 1, 100)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_42 (Bat  (None, 19, 1, 100)       400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_42 (Dropout)        (None, 19, 1, 100)        0         \n",
      "                                                                 \n",
      " conv2d_43 (Conv2D)          (None, 19, 1, 200)        200200    \n",
      "                                                                 \n",
      " max_pooling2d_43 (MaxPoolin  (None, 7, 1, 200)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_43 (Bat  (None, 7, 1, 200)        800       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_43 (Dropout)        (None, 7, 1, 200)         0         \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 1400)              0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 4)                 5604      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 275,479\n",
      "Trainable params: 274,729\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "109/109 [==============================] - 5s 40ms/step - loss: 2.0292 - accuracy: 0.3164 - val_loss: 4.9543 - val_accuracy: 0.2747\n",
      "Epoch 2/25\n",
      "109/109 [==============================] - 4s 39ms/step - loss: 1.4922 - accuracy: 0.3925 - val_loss: 1.2355 - val_accuracy: 0.4420\n",
      "Epoch 3/25\n",
      "109/109 [==============================] - 4s 38ms/step - loss: 1.2840 - accuracy: 0.4619 - val_loss: 1.2755 - val_accuracy: 0.4140\n",
      "Epoch 4/25\n",
      "109/109 [==============================] - 4s 38ms/step - loss: 1.1739 - accuracy: 0.5024 - val_loss: 1.2602 - val_accuracy: 0.4407\n",
      "Epoch 5/25\n",
      "109/109 [==============================] - 4s 38ms/step - loss: 1.0859 - accuracy: 0.5506 - val_loss: 1.1142 - val_accuracy: 0.4980\n",
      "Epoch 6/25\n",
      "109/109 [==============================] - 4s 38ms/step - loss: 1.0085 - accuracy: 0.5864 - val_loss: 1.1723 - val_accuracy: 0.4907\n",
      "Epoch 7/25\n",
      "109/109 [==============================] - 4s 38ms/step - loss: 0.9389 - accuracy: 0.6138 - val_loss: 1.0628 - val_accuracy: 0.5500\n",
      "Epoch 8/25\n",
      "109/109 [==============================] - 4s 38ms/step - loss: 0.9007 - accuracy: 0.6328 - val_loss: 1.0673 - val_accuracy: 0.5540\n",
      "Epoch 9/25\n",
      "109/109 [==============================] - 4s 38ms/step - loss: 0.8418 - accuracy: 0.6578 - val_loss: 1.0502 - val_accuracy: 0.5513\n",
      "Epoch 10/25\n",
      "109/109 [==============================] - 4s 38ms/step - loss: 0.8016 - accuracy: 0.6852 - val_loss: 0.9748 - val_accuracy: 0.6113\n",
      "Epoch 11/25\n",
      "109/109 [==============================] - 4s 38ms/step - loss: 0.7483 - accuracy: 0.7086 - val_loss: 0.9702 - val_accuracy: 0.6100\n",
      "Epoch 12/25\n",
      "109/109 [==============================] - 4s 38ms/step - loss: 0.7167 - accuracy: 0.7249 - val_loss: 0.9167 - val_accuracy: 0.6420\n",
      "Epoch 13/25\n",
      "109/109 [==============================] - 4s 38ms/step - loss: 0.6832 - accuracy: 0.7336 - val_loss: 0.9494 - val_accuracy: 0.6233\n",
      "Epoch 14/25\n",
      "109/109 [==============================] - 4s 38ms/step - loss: 0.6406 - accuracy: 0.7425 - val_loss: 0.9634 - val_accuracy: 0.6167\n",
      "Epoch 15/25\n",
      "109/109 [==============================] - 4s 38ms/step - loss: 0.6202 - accuracy: 0.7598 - val_loss: 0.9413 - val_accuracy: 0.6313\n",
      "Epoch 16/25\n",
      "109/109 [==============================] - 4s 38ms/step - loss: 0.5950 - accuracy: 0.7737 - val_loss: 0.9398 - val_accuracy: 0.6440\n",
      "Epoch 17/25\n",
      "109/109 [==============================] - 4s 38ms/step - loss: 0.5559 - accuracy: 0.7872 - val_loss: 0.9609 - val_accuracy: 0.6253\n",
      "Epoch 18/25\n",
      "109/109 [==============================] - 4s 38ms/step - loss: 0.5340 - accuracy: 0.7897 - val_loss: 0.9502 - val_accuracy: 0.6433\n",
      "Epoch 19/25\n",
      "109/109 [==============================] - 4s 38ms/step - loss: 0.5229 - accuracy: 0.7980 - val_loss: 0.9219 - val_accuracy: 0.6427\n",
      "Epoch 20/25\n",
      "109/109 [==============================] - 4s 38ms/step - loss: 0.5057 - accuracy: 0.8022 - val_loss: 0.9872 - val_accuracy: 0.6500\n",
      "Epoch 21/25\n",
      "109/109 [==============================] - 4s 38ms/step - loss: 0.4587 - accuracy: 0.8231 - val_loss: 0.9364 - val_accuracy: 0.6740\n",
      "Epoch 22/25\n",
      "109/109 [==============================] - 4s 38ms/step - loss: 0.4612 - accuracy: 0.8257 - val_loss: 0.9639 - val_accuracy: 0.6607\n",
      "Epoch 23/25\n",
      "109/109 [==============================] - 4s 38ms/step - loss: 0.4379 - accuracy: 0.8328 - val_loss: 1.0706 - val_accuracy: 0.6267\n",
      "Epoch 24/25\n",
      "109/109 [==============================] - 4s 38ms/step - loss: 0.4356 - accuracy: 0.8366 - val_loss: 1.0109 - val_accuracy: 0.6513\n",
      "Epoch 25/25\n",
      "109/109 [==============================] - 4s 38ms/step - loss: 0.4053 - accuracy: 0.8466 - val_loss: 1.0602 - val_accuracy: 0.6507\n",
      "Test accuracy of the basic CNN model: 0.6523702144622803\n"
     ]
    }
   ],
   "source": [
    "t = 1000\n",
    "## Use same train valid split\n",
    "x_train,y_train = data_prep_timed(X_train,Y_train,2,2,True,t)\n",
    "x_valid,y_valid = data_prep_timed(X_valid,Y_valid,2,2,True,t)\n",
    "X_test_prep,y_test_prep = data_prep_timed(X_test,Y_test,2,2,True,t)\n",
    "\n",
    "# Converting the labels to categorical variables for multiclass classification\n",
    "y_train = to_categorical(y_train, 4)\n",
    "y_valid = to_categorical(y_valid, 4)\n",
    "y_test = to_categorical(y_test_prep, 4)\n",
    "\n",
    "# Adding width of the segment to be 1\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
    "x_valid = x_valid.reshape(x_valid.shape[0], x_valid.shape[1], x_train.shape[2], 1)\n",
    "x_test = X_test_prep.reshape(X_test_prep.shape[0], X_test_prep.shape[1], X_test_prep.shape[2], 1)\n",
    "\n",
    "\n",
    "# Reshaping the training and validation dataset\n",
    "x_train = np.swapaxes(x_train, 1,3)\n",
    "x_train = np.swapaxes(x_train, 1,2)\n",
    "x_valid = np.swapaxes(x_valid, 1,3)\n",
    "x_valid = np.swapaxes(x_valid, 1,2)\n",
    "x_test = np.swapaxes(x_test, 1,3)\n",
    "x_test = np.swapaxes(x_test, 1,2)\n",
    "\n",
    "# Building the CNN model using sequential class\n",
    "t_cnn_model = Sequential()\n",
    "\n",
    "# Conv. block 1\n",
    "t_cnn_model.add(Conv2D(filters=25, kernel_size=(10,1), padding='same', activation='elu', input_shape=x_train.shape[1:4]))\n",
    "t_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same')) # Read the keras documentation\n",
    "t_cnn_model.add(BatchNormalization())\n",
    "t_cnn_model.add(Dropout(0.5))\n",
    "\n",
    "# Conv. block 2\n",
    "t_cnn_model.add(Conv2D(filters=50, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "t_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "t_cnn_model.add(BatchNormalization())\n",
    "t_cnn_model.add(Dropout(0.5))\n",
    "\n",
    "# Conv. block 3\n",
    "t_cnn_model.add(Conv2D(filters=100, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "t_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "t_cnn_model.add(BatchNormalization())\n",
    "t_cnn_model.add(Dropout(0.5))\n",
    "\n",
    "# Conv. block 4\n",
    "t_cnn_model.add(Conv2D(filters=200, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "t_cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "t_cnn_model.add(BatchNormalization())\n",
    "t_cnn_model.add(Dropout(0.5))\n",
    "\n",
    "# Output layer with Softmax activation\n",
    "t_cnn_model.add(Flatten()) # Flattens the input\n",
    "t_cnn_model.add(Dense(4, activation='softmax')) # Output FC layer with softmax activation\n",
    "\n",
    "\n",
    "# Printing the model summary\n",
    "t_cnn_model.summary()\n",
    "\n",
    "t_cnn_model.compile(loss='categorical_crossentropy',\n",
    "                 optimizer=cnn_optimizer,\n",
    "                 metrics=['accuracy'])\n",
    "t_cnn_model_results = t_cnn_model.fit(x_train,\n",
    "             y_train,\n",
    "             batch_size=64,\n",
    "             epochs=25,\n",
    "             validation_data=(x_valid, y_valid), verbose=True)\n",
    "\n",
    "tscore = t_cnn_model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test accuracy of the basic CNN model:',tscore[1])\n",
    "tscores.append(tscore[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5761851072311401,\n",
       " 0.6574491858482361,\n",
       " 0.6625282168388367,\n",
       " 0.6551918983459473,\n",
       " 0.6055305004119873,\n",
       " 0.6523702144622803]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x28d07a81490>]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([200,400,500,600,800,1000],tscores,)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
